{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Ultimate Ansible Bootcamp Chapter1: Introduction to Ansible Chapter2: Path to Automation Chapter3 : Setting up Learning Environment Chapter 4: Ad Hoc Server Management Management Chapter 5: Playbooks - Learning to Write Infrastructure as a Code Chapter 6: Working with Roles Chapter 7: Variables and Templates Chapter 8: Ansible Galaxy Chapter 9: Control Structures Chapter10: Magic Variables and Multiple Environments Chapter11: Vault Chapter12: Deployment License (CC-BY-NC-ND) Ultimate Ansible Bootcamp by School of Devops is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License .","title":"Home"},{"location":"#ultimate-ansible-bootcamp","text":"Chapter1: Introduction to Ansible Chapter2: Path to Automation Chapter3 : Setting up Learning Environment Chapter 4: Ad Hoc Server Management Management Chapter 5: Playbooks - Learning to Write Infrastructure as a Code Chapter 6: Working with Roles Chapter 7: Variables and Templates Chapter 8: Ansible Galaxy Chapter 9: Control Structures Chapter10: Magic Variables and Multiple Environments Chapter11: Vault Chapter12: Deployment","title":"Ultimate Ansible Bootcamp"},{"location":"#license-cc-by-nc-nd","text":"Ultimate Ansible Bootcamp by School of Devops is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License .","title":"License (CC-BY-NC-ND)"},{"location":"ad-hoc/","text":"Getting Started with Ansible (Ad Hoc Server Management) Creating Project Specific Ansible Configuration The default configurations for ansible resides at /etc/ansible/ansible.cfg. Instead of relying on defaults, we are going to creates a custom configuration file for our project. The advantage with that is we could take this configurations on any host and execute it the same way, without touching the default system configurations. This custom configurations will essentially override the values in /etc/ansible/ansible/cfg. Ansible configuration file Change into /vagrant/code/chap3 directory on your ansible host. Create a file called ansible.cfg Add the following contents to the file. On Ansible Control node, cd chap4 ansible --version Create ansible.cfg in chap4 [defaults] remote_user = devops inventory = environments/prod retry_files_save_path = /tmp host_key_checking = False log_path=~/ansible.log Validate that your new configs are picked up, ansible --version ansible-config dump Creating Host Inventory Since you are going to create a environment specific inventory, create a environments directory and a file inside it called prod mkdir environments Create inventory file file: environments/prod Let's create three groups as follows, [local] localhost ansible_connection=local [lb] lb [app] app1 app2 [db] db [prod:children] lb app db First group contains the localhost, the control host. Since it does not need to be connected over ssh, it mandates we add ansible_connection=local option Second group contains Application Servers. We will add two app servers to this group. Third group holds the information about the database servers. The inventory file should look like below. Working with Inventory Command ansible-inventory --help ansible-inventory --list ansible-inventory --graph Ansible ping We will use Ansible to make sure all the hosts are reachable ansible all -m ping [Output] lb | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } app1 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } app2 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } db | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } Ad Hoc commands Try running following fire-and-forget Ad-Hoc commands... Run hostname command on all hosts Let us print the hostname of all the hosts ansible all -a hostname [output] localhost | SUCCESS | rc=0 >> ansible 192.168.61.11 | SUCCESS | rc=0 >> db 192.168.61.12 | SUCCESS | rc=0 >> app 192.168.61.13 | SUCCESS | rc=0 >> app Check the uptime How long the hosts are up ? ansible all -a uptime [Output] localhost | SUCCESS | rc=0 >> 13:17:13 up 2:21, 1 user, load average: 0.16, 0.03, 0.01 192.168.61.12 | SUCCESS | rc=0 >> 13:17:14 up 1:50, 2 users, load average: 0.00, 0.00, 0.00 192.168.61.13 | SUCCESS | rc=0 >> 13:17:14 up 1:47, 2 users, load average: 0.00, 0.00, 0.00 192.168.61.11 | SUCCESS | rc=0 >> 13:17:14 up 1:36, 2 users, load average: 0.00, 0.00, 0.00 Check memory info on app servers Does my app servers have any disk space free ? ansible app -a free [Output] 192.168.61.13 | SUCCESS | rc=0 >> total used free shared buffers cached Mem: 372916 121480 251436 776 11160 46304 -/+ buffers/cache: 64016 308900 Swap: 4128764 0 4128764 192.168.61.12 | SUCCESS | rc=0 >> total used free shared buffers cached Mem: 372916 121984 250932 776 11228 46336 -/+ buffers/cache: 64420 308496 Swap: 4128764 0 4128764 Installing packages Let us install nano editor on app servers ansible app -a \"yum install -y nano\" This command will fail. [Output] 192.168.61.13 | FAILED | rc=1 >> Loaded plugins: fastestmirror, prioritiesYou need to be root to perform this command. 192.168.61.12 | FAILED | rc=1 >> Loaded plugins: fastestmirror, prioritiesYou need to be root to perform this command. Run the fillowing command with sudo permissions. ansible app -s -a \"yum install -y nano\" This will install docker in our app servers [Output] ================================================================================ Package Arch Version Repository Size ================================================================================ Installing: nano x86_64 2.0.9-7.el6 base 436 k Transaction Summary ================================================================================ Install 1 Package(s) Total download size: 436 k Installed size: 1.5 M Downloading Packages: Running rpm_check_debug Running Transaction Test Transaction Test Succeeded Running Transaction Installing : nano-2.0.9-7.el6.x86_64 1/1 Verifying : nano-2.0.9-7.el6.x86_64 1/1 Installed: nano.x86_64 0:2.0.9-7.el6 Complete! Running commands one machine at a time Do you want a command to run on one machine at a time ? ansible all -f 1 -a \"free\" Using modules to manage the state of infrastructure Creating users and groups using user and group To create a group ansible app -s -m group -a \"name=admin state=present\" The output will be, 192.168.61.13 | SUCCESS => { \"changed\": true, \"gid\": 501, \"name\": \"admin\", \"state\": \"present\", \"system\": false } 192.168.61.12 | SUCCESS => { \"changed\": true, \"gid\": 501, \"name\": \"admin\", \"state\": \"present\", \"system\": false } To create a user ansible app -s -m user -a \"name=devops group=admin createhome=yes\" This will create user devops , 192.168.61.13 | SUCCESS => { \"changed\": true, \"comment\": \"\", \"createhome\": true, \"group\": 501, \"home\": \"/home/devops\", \"name\": \"devops\", \"shell\": \"/bin/bash\", \"state\": \"present\", \"system\": false, \"uid\": 501 } 192.168.61.12 | SUCCESS => { \"changed\": true, \"comment\": \"\", \"createhome\": true, \"group\": 501, \"home\": \"/home/devops\", \"name\": \"devops\", \"shell\": \"/bin/bash\", \"state\": \"present\", \"system\": false, \"uid\": 501 } Copy a file using copy modules We will copy file from control node to app servers. touch /tmp/test.txt ansible app -m copy -a \"src=/tmp/test.txt dest=/tmp/test.txt\" File will be copied over to our app server machines... 192.168.61.13 | SUCCESS => { \"changed\": true, \"checksum\": \"3160f8f941c330444aac253a9e6420cd1a65bfe2\", \"dest\": \"/tmp/test.txt\", \"gid\": 500, \"group\": \"vagrant\", \"md5sum\": \"9052de4cff7e8a18de586f785e711b97\", \"mode\": \"0664\", \"owner\": \"vagrant\", \"size\": 11, \"src\": \"/home/vagrant/.ansible/tmp/ansible-tmp-1472991990.29-63683023616899/source\", \"state\": \"file\", \"uid\": 500 } 192.168.61.12 | SUCCESS => { \"changed\": true, \"checksum\": \"3160f8f941c330444aac253a9e6420cd1a65bfe2\", \"dest\": \"/tmp/test.txt\", \"gid\": 500, \"group\": \"vagrant\", \"md5sum\": \"9052de4cff7e8a18de586f785e711b97\", \"mode\": \"0664\", \"owner\": \"vagrant\", \"size\": 11, \"src\": \"/home/vagrant/.ansible/tmp/ansible-tmp-1472991990.26-218089785548663/source\", \"state\": \"file\", \"uid\": 500 } Exercises: Add another system group (not inventory group) called lb in inventory with respective host ip Add a system user called joe on all app servers. Make sure that the user has a home directory Install package vim using the correct Ad-Hoc command Examine all the available module http://docs.ansible.com/ansible/modules_by_category.html Find out the difference between the command module and shell module. Try running the following command with both these modules, \"free | grep -i swap\" Use command module to show uptime on the host Install docker-engine using the yum/apt module Using docker-image module, pull hello-world image on web server","title":"Ad Hoc Server Maangement with Ansible"},{"location":"ad-hoc/#getting-started-with-ansible-ad-hoc-server-management","text":"","title":"Getting Started with Ansible (Ad Hoc Server Management)"},{"location":"ad-hoc/#creating-project-specific-ansible-configuration","text":"The default configurations for ansible resides at /etc/ansible/ansible.cfg. Instead of relying on defaults, we are going to creates a custom configuration file for our project. The advantage with that is we could take this configurations on any host and execute it the same way, without touching the default system configurations. This custom configurations will essentially override the values in /etc/ansible/ansible/cfg.","title":"Creating Project Specific Ansible Configuration"},{"location":"ad-hoc/#ansible-configuration-file","text":"Change into /vagrant/code/chap3 directory on your ansible host. Create a file called ansible.cfg Add the following contents to the file. On Ansible Control node, cd chap4 ansible --version Create ansible.cfg in chap4 [defaults] remote_user = devops inventory = environments/prod retry_files_save_path = /tmp host_key_checking = False log_path=~/ansible.log Validate that your new configs are picked up, ansible --version ansible-config dump","title":"Ansible configuration file"},{"location":"ad-hoc/#creating-host-inventory","text":"Since you are going to create a environment specific inventory, create a environments directory and a file inside it called prod mkdir environments Create inventory file file: environments/prod Let's create three groups as follows, [local] localhost ansible_connection=local [lb] lb [app] app1 app2 [db] db [prod:children] lb app db First group contains the localhost, the control host. Since it does not need to be connected over ssh, it mandates we add ansible_connection=local option Second group contains Application Servers. We will add two app servers to this group. Third group holds the information about the database servers. The inventory file should look like below.","title":"Creating Host Inventory"},{"location":"ad-hoc/#working-with-inventory-command","text":"ansible-inventory --help ansible-inventory --list ansible-inventory --graph","title":"Working with Inventory Command"},{"location":"ad-hoc/#ansible-ping","text":"We will use Ansible to make sure all the hosts are reachable ansible all -m ping [Output] lb | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } app1 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } app2 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } db | SUCCESS => { \"changed\": false, \"ping\": \"pong\" }","title":"Ansible ping"},{"location":"ad-hoc/#ad-hoc-commands","text":"Try running following fire-and-forget Ad-Hoc commands...","title":"Ad Hoc commands"},{"location":"ad-hoc/#run-hostname-command-on-all-hosts","text":"Let us print the hostname of all the hosts ansible all -a hostname [output] localhost | SUCCESS | rc=0 >> ansible 192.168.61.11 | SUCCESS | rc=0 >> db 192.168.61.12 | SUCCESS | rc=0 >> app 192.168.61.13 | SUCCESS | rc=0 >> app","title":"Run hostname command on all hosts"},{"location":"ad-hoc/#check-the-uptime","text":"How long the hosts are up ? ansible all -a uptime [Output] localhost | SUCCESS | rc=0 >> 13:17:13 up 2:21, 1 user, load average: 0.16, 0.03, 0.01 192.168.61.12 | SUCCESS | rc=0 >> 13:17:14 up 1:50, 2 users, load average: 0.00, 0.00, 0.00 192.168.61.13 | SUCCESS | rc=0 >> 13:17:14 up 1:47, 2 users, load average: 0.00, 0.00, 0.00 192.168.61.11 | SUCCESS | rc=0 >> 13:17:14 up 1:36, 2 users, load average: 0.00, 0.00, 0.00","title":"Check the uptime"},{"location":"ad-hoc/#check-memory-info-on-app-servers","text":"Does my app servers have any disk space free ? ansible app -a free [Output] 192.168.61.13 | SUCCESS | rc=0 >> total used free shared buffers cached Mem: 372916 121480 251436 776 11160 46304 -/+ buffers/cache: 64016 308900 Swap: 4128764 0 4128764 192.168.61.12 | SUCCESS | rc=0 >> total used free shared buffers cached Mem: 372916 121984 250932 776 11228 46336 -/+ buffers/cache: 64420 308496 Swap: 4128764 0 4128764","title":"Check memory info on app servers"},{"location":"ad-hoc/#installing-packages","text":"Let us install nano editor on app servers ansible app -a \"yum install -y nano\" This command will fail. [Output] 192.168.61.13 | FAILED | rc=1 >> Loaded plugins: fastestmirror, prioritiesYou need to be root to perform this command. 192.168.61.12 | FAILED | rc=1 >> Loaded plugins: fastestmirror, prioritiesYou need to be root to perform this command. Run the fillowing command with sudo permissions. ansible app -s -a \"yum install -y nano\" This will install docker in our app servers [Output] ================================================================================ Package Arch Version Repository Size ================================================================================ Installing: nano x86_64 2.0.9-7.el6 base 436 k Transaction Summary ================================================================================ Install 1 Package(s) Total download size: 436 k Installed size: 1.5 M Downloading Packages: Running rpm_check_debug Running Transaction Test Transaction Test Succeeded Running Transaction Installing : nano-2.0.9-7.el6.x86_64 1/1 Verifying : nano-2.0.9-7.el6.x86_64 1/1 Installed: nano.x86_64 0:2.0.9-7.el6 Complete!","title":"Installing packages"},{"location":"ad-hoc/#running-commands-one-machine-at-a-time","text":"Do you want a command to run on one machine at a time ? ansible all -f 1 -a \"free\"","title":"Running commands one machine at a time"},{"location":"ad-hoc/#using-modules-to-manage-the-state-of-infrastructure","text":"","title":"Using modules to manage the state of infrastructure"},{"location":"ad-hoc/#creating-users-and-groups-using-user-and-group","text":"To create a group ansible app -s -m group -a \"name=admin state=present\" The output will be, 192.168.61.13 | SUCCESS => { \"changed\": true, \"gid\": 501, \"name\": \"admin\", \"state\": \"present\", \"system\": false } 192.168.61.12 | SUCCESS => { \"changed\": true, \"gid\": 501, \"name\": \"admin\", \"state\": \"present\", \"system\": false } To create a user ansible app -s -m user -a \"name=devops group=admin createhome=yes\" This will create user devops , 192.168.61.13 | SUCCESS => { \"changed\": true, \"comment\": \"\", \"createhome\": true, \"group\": 501, \"home\": \"/home/devops\", \"name\": \"devops\", \"shell\": \"/bin/bash\", \"state\": \"present\", \"system\": false, \"uid\": 501 } 192.168.61.12 | SUCCESS => { \"changed\": true, \"comment\": \"\", \"createhome\": true, \"group\": 501, \"home\": \"/home/devops\", \"name\": \"devops\", \"shell\": \"/bin/bash\", \"state\": \"present\", \"system\": false, \"uid\": 501 }","title":"Creating users and groups using user and group"},{"location":"ad-hoc/#copy-a-file-using-copy-modules","text":"We will copy file from control node to app servers. touch /tmp/test.txt ansible app -m copy -a \"src=/tmp/test.txt dest=/tmp/test.txt\" File will be copied over to our app server machines... 192.168.61.13 | SUCCESS => { \"changed\": true, \"checksum\": \"3160f8f941c330444aac253a9e6420cd1a65bfe2\", \"dest\": \"/tmp/test.txt\", \"gid\": 500, \"group\": \"vagrant\", \"md5sum\": \"9052de4cff7e8a18de586f785e711b97\", \"mode\": \"0664\", \"owner\": \"vagrant\", \"size\": 11, \"src\": \"/home/vagrant/.ansible/tmp/ansible-tmp-1472991990.29-63683023616899/source\", \"state\": \"file\", \"uid\": 500 } 192.168.61.12 | SUCCESS => { \"changed\": true, \"checksum\": \"3160f8f941c330444aac253a9e6420cd1a65bfe2\", \"dest\": \"/tmp/test.txt\", \"gid\": 500, \"group\": \"vagrant\", \"md5sum\": \"9052de4cff7e8a18de586f785e711b97\", \"mode\": \"0664\", \"owner\": \"vagrant\", \"size\": 11, \"src\": \"/home/vagrant/.ansible/tmp/ansible-tmp-1472991990.26-218089785548663/source\", \"state\": \"file\", \"uid\": 500 }","title":"Copy a file using copy modules"},{"location":"ad-hoc/#exercises","text":"Add another system group (not inventory group) called lb in inventory with respective host ip Add a system user called joe on all app servers. Make sure that the user has a home directory Install package vim using the correct Ad-Hoc command Examine all the available module http://docs.ansible.com/ansible/modules_by_category.html Find out the difference between the command module and shell module. Try running the following command with both these modules, \"free | grep -i swap\" Use command module to show uptime on the host Install docker-engine using the yum/apt module Using docker-image module, pull hello-world image on web server","title":"Exercises:"},{"location":"ansible-pull/","text":"ansible-pull -U https://github.com/schoolofdevops/ansible-repo -i myhosts.ini Connects to git and checks out the repo Finds fqdn.yml or local.yml Launches the playbook run ansible-pull can * -C CHECKOUT, --checkout=CHECKOUT Accept the git branch/tag/commit to Pull * -o, --only-if-changed ansible-pull -U https://github.com/schoolofdevops/ansible-repo -i myhosts.ini Starting Ansible Pull at 2016-11-15 14:54:53 /usr/bin/ansible-pull -U https://github.com/schoolofdevops/ansible-repo -i myhosts.ini localhost | SUCCESS => { \"after\": \"f93d954e4bdc3aebbe4fba690ceccf1f8285e508\", \"before\": \"f93d954e4bdc3aebbe4fba690ceccf1f8285e508\", \"changed\": false, \"warnings\": [ \"Your git version is too old to fully support the depth argument. Falling back to full checkouts.\" ] } [WARNING]: Your git version is too old to fully support the depth argument. Falling back to full checkouts. PLAY [Base Configurations for ALL hosts] *************************************** TASK [setup] ******************************************************************* ok: [localhost] TASK [create admin user] ******************************************************* ok: [localhost] TASK [remove dojo] ************************************************************* ok: [localhost] TASK [install tree] ************************************************************ ok: [localhost] TASK [install ntp] ************************************************************* ok: [localhost] TASK [start ntp service] ******************************************************* ok: [localhost] PLAY RECAP ********************************************************************* localhost : ok=6 changed=0 unreachable=0 failed=0 ansible-pull -U https://github.com/schoolofdevops/ansible-repo -i myhosts.ini Starting Ansible Pull at 2016-11-15 14:54:53 /usr/bin/ansible-pull -U https://github.com/schoolofdevops/ansible-repo -i myhosts.ini localhost | SUCCESS => { \"after\": \"f93d954e4bdc3aebbe4fba690ceccf1f8285e508\", \"before\": \"f93d954e4bdc3aebbe4fba690ceccf1f8285e508\", \"changed\": false, \"warnings\": [ \"Your git version is too old to fully support the depth argument. Falling back to full checkouts.\" ] } [WARNING]: Your git version is too old to fully support the depth argument. Falling back to full checkouts. PLAY [Base Configurations for ALL hosts] *************************************** TASK [setup] ******************************************************************* ok: [localhost] TASK [create admin user] ******************************************************* ok: [localhost] TASK [remove dojo] ************************************************************* ok: [localhost] TASK [install tree] ************************************************************ ok: [localhost] TASK [install ntp] ************************************************************* ok: [localhost] TASK [start ntp service] ******************************************************* ok: [localhost] PLAY RECAP ********************************************************************* localhost : ok=6 changed=0 unreachable=0 failed=0","title":"Ansible Tower"},{"location":"ansible-tower/","text":"Commercial Version of Ansible Self Hosted (trial version) Standard and Premium USD 10,000 for 100 nodes UI to manage Ansible Infrastructure Reporting, Logs RBAC,","title":"Ansible tower"},{"location":"ansible-vault/","text":"Why to use Vault To maintain sensitive data e.g. passwords/creds, keys etc. Version control encrypted files instead of plain text ansible-vault utility How ? Used AES Cipher Symmetric Key What can be encrypted ? Structured data (yaml, json) Var files group_vars/hostvars include_vars or var_files var files passed at command line with \"-e @file\" Tasks (however not very common) Arbitory Files Strings (newly added) What can not be encrypted ? Templates How to encrypt/decrypt Using --ask-vault-pass Using --vault-password-file ansible-vault Operations encrypt decrypt create rekey edit Examples Running Playbooks with Vault ansible-playbook site.yml --ask-vault-pass ansible-playbook site.yml --vault-password-file ~/.vault_pass.txt Automating Rekeying Process --new-vault-password-file=NEW_VAULT_PASSWORD_FILE new vault password file for rekey Lab : Encrypting and decrypting with single key mkdir vault file: vault/api_keys USER: devops API_KEY: GUIFEHR3485y384H78435YYF89GUW03RIUWFHI TOKEN: 8549JBHBHUPIYHSL602JHU Encrypting file cd vault ansible-vault encrypt api_keys cat api_keys ansible-vault view api_keys write a playbook to use encrypted file file: test_vault.yml --- - name: testing ansible vault hosts: 'local:app' become: true tasks: - name: copy a file containing api keys copy: src: vault/api_keys dest: /root/.api_keys owner: root group: root mode: 0400 apply ansible-playbook test_vault.yml ansible-playbook test_vault.yml --ask-vault-pass Using a password file file ~/.vault password1 profile passowrd file ansible-playbook test_vault.yml --vault-password-file ~/.vault New Vault: Multiple vault ids and encrypting strings create vault password file for vault id prod file ~/.vault_prod prodpassword Create files to encrypt file: creds mysql_root_password: password create copies of it cp creds staging cp creds prod encrypt ansible-vault encrypt creds ansible-vault encrypt staging --vault-id staging@prompt ansible-vault encrypt prod --vault-id prod@~/.vault_prod decrypt all ansible-vault decrypt --vault-id staging@prompt staging --vault-id prod@~/.vault_prod --vault-id @prompt creds creating individual vaules ansible-vault encrypt_string --vault-id prod@~/.vault_prod 'password' --name 'mysql_root_password'","title":"Encrypting sensitive data with Ansible Vault"},{"location":"ansible-vault/#why-to-use-vault","text":"To maintain sensitive data e.g. passwords/creds, keys etc. Version control encrypted files instead of plain text ansible-vault utility","title":"Why to use Vault"},{"location":"ansible-vault/#how","text":"Used AES Cipher Symmetric Key","title":"How ?"},{"location":"ansible-vault/#what-can-be-encrypted","text":"Structured data (yaml, json) Var files group_vars/hostvars include_vars or var_files var files passed at command line with \"-e @file\" Tasks (however not very common) Arbitory Files Strings (newly added)","title":"What can be encrypted ?"},{"location":"ansible-vault/#what-can-not-be-encrypted","text":"Templates","title":"What can not be encrypted ?"},{"location":"ansible-vault/#how-to-encryptdecrypt","text":"Using --ask-vault-pass Using --vault-password-file","title":"How to encrypt/decrypt"},{"location":"ansible-vault/#ansible-vault-operations","text":"encrypt decrypt create rekey edit","title":"ansible-vault Operations"},{"location":"ansible-vault/#examples","text":"Running Playbooks with Vault ansible-playbook site.yml --ask-vault-pass ansible-playbook site.yml --vault-password-file ~/.vault_pass.txt Automating Rekeying Process --new-vault-password-file=NEW_VAULT_PASSWORD_FILE new vault password file for rekey","title":"Examples"},{"location":"ansible-vault/#lab-encrypting-and-decrypting-with-single-key","text":"mkdir vault file: vault/api_keys USER: devops API_KEY: GUIFEHR3485y384H78435YYF89GUW03RIUWFHI TOKEN: 8549JBHBHUPIYHSL602JHU Encrypting file cd vault ansible-vault encrypt api_keys cat api_keys ansible-vault view api_keys write a playbook to use encrypted file file: test_vault.yml --- - name: testing ansible vault hosts: 'local:app' become: true tasks: - name: copy a file containing api keys copy: src: vault/api_keys dest: /root/.api_keys owner: root group: root mode: 0400 apply ansible-playbook test_vault.yml ansible-playbook test_vault.yml --ask-vault-pass Using a password file file ~/.vault password1 profile passowrd file ansible-playbook test_vault.yml --vault-password-file ~/.vault","title":"Lab : Encrypting and decrypting with single key"},{"location":"ansible-vault/#new-vault-multiple-vault-ids-and-encrypting-strings","text":"create vault password file for vault id prod file ~/.vault_prod prodpassword Create files to encrypt file: creds mysql_root_password: password create copies of it cp creds staging cp creds prod encrypt ansible-vault encrypt creds ansible-vault encrypt staging --vault-id staging@prompt ansible-vault encrypt prod --vault-id prod@~/.vault_prod decrypt all ansible-vault decrypt --vault-id staging@prompt staging --vault-id prod@~/.vault_prod --vault-id @prompt creds creating individual vaules ansible-vault encrypt_string --vault-id prod@~/.vault_prod 'password' --name 'mysql_root_password'","title":"New Vault: Multiple vault ids and encrypting strings"},{"location":"ansible-windows/","text":"Preparing Ansible host sudo yum install python-pip sudo pip install \"pywinrm>=0.1.1\" Preparing Windows Host Create a file and paste the below github content and save \u201cPowerShell Scripts (* .ps1)\u201d. https://github.com/ansible/ansible/blob/devel/examples/scripts/ConfigureRemotingForAnsible.ps1 Double Click the file or open powershell and Execute it from the file path. winrm will be configured Setting up inventory and inventory vars Add windows host to inventory by editing myhosts.ini [windows] windows_host_ip_or_hostname Create group vars for windows group - Create group_vars/windows.yml ansible_ssh_user: <admin user> ansible_ssh_pass: <admin user password> ansible_ssh_port: 5986 ansible_connection: winrm ansible_winrm_server_cert_validation: ignore Validate Connectivity ansible windows -i host -m win_ping ansible windows -i host -m setup Create a Sample Playbook : windows.yml --- - name: test raw module hosts: windows tasks: - name: run ipconfig raw: ipconfig register: ipconfig - debug: var=ipconfig - name: test stat module on file win_stat: path=\"C:/Windows/win.ini\" register: stat_file - debug: var=stat_file - name: check stat_file result assert: that: - \"stat_file.stat.exists\" - \"not stat_file.stat.isdir\" - \"stat_file.stat.size > 0\" - \"stat_file.stat.md5\" - name: Install IIS win_feature: name: \"Web-Server\" state: absent restart: yes include_sub_features: yes include_management_tools: yes Execute Playbook as ansible-playbook windows.yml Reference http://darrylcauldwell.com/how-to-setup-an-ansible-test-lab-for-windows-managed-nodes-custom-windows-modules/ http://docs.ansible.com/ansible/intro_windows.html","title":"Ansible on Windows"},{"location":"ansible-windows/#preparing-ansible-host","text":"sudo yum install python-pip sudo pip install \"pywinrm>=0.1.1\"","title":"Preparing Ansible host"},{"location":"ansible-windows/#preparing-windows-host","text":"Create a file and paste the below github content and save \u201cPowerShell Scripts (* .ps1)\u201d. https://github.com/ansible/ansible/blob/devel/examples/scripts/ConfigureRemotingForAnsible.ps1 Double Click the file or open powershell and Execute it from the file path. winrm will be configured","title":"Preparing Windows Host"},{"location":"ansible-windows/#setting-up-inventory-and-inventory-vars","text":"Add windows host to inventory by editing myhosts.ini [windows] windows_host_ip_or_hostname Create group vars for windows group - Create group_vars/windows.yml ansible_ssh_user: <admin user> ansible_ssh_pass: <admin user password> ansible_ssh_port: 5986 ansible_connection: winrm ansible_winrm_server_cert_validation: ignore Validate Connectivity ansible windows -i host -m win_ping ansible windows -i host -m setup Create a Sample Playbook : windows.yml --- - name: test raw module hosts: windows tasks: - name: run ipconfig raw: ipconfig register: ipconfig - debug: var=ipconfig - name: test stat module on file win_stat: path=\"C:/Windows/win.ini\" register: stat_file - debug: var=stat_file - name: check stat_file result assert: that: - \"stat_file.stat.exists\" - \"not stat_file.stat.isdir\" - \"stat_file.stat.size > 0\" - \"stat_file.stat.md5\" - name: Install IIS win_feature: name: \"Web-Server\" state: absent restart: yes include_sub_features: yes include_management_tools: yes Execute Playbook as ansible-playbook windows.yml","title":"Setting up inventory and inventory vars"},{"location":"ansible-windows/#reference","text":"http://darrylcauldwell.com/how-to-setup-an-ansible-test-lab-for-windows-managed-nodes-custom-windows-modules/ http://docs.ansible.com/ansible/intro_windows.html","title":"Reference"},{"location":"comparison/","text":"Ansible vs Chef/Puppet applying a role applies only tasks/main.yml. There is no direct way to apply individual tasks e.g. apache::install. Puppet/chef both have this. Registered variables: its possible to register the result of a command as a variable, based on which decisions can be made, as well as results can be passed to next tasks. Push vs Pull Model Scale. Puppet/Chef can scale better imho Ansible Tower is expensive, not per node.","title":"Comparison"},{"location":"control_structures/","text":"Control Structures In this chapter, we will learn about the aspects of ansible that can change the execution flow. This includes, Iterators/loops Conditionals Tags Conditional inclusions Refactoring systems playbook Iterating over a list of items to install packages Create a list of packages Let us create the following list of packages in base role. Edit group_vars/prod.yml and put systems: packages: - ntp - tree - vim Also edit roles/systems/tasks/main.yml to iterate over this list of items and install packages - name: install common systems packages package: name: \"{{ item }}\" state: installed with_items: - \"{{ systems.packages }}\" apply ansible-playbook app.yml Iterating over a hash table/dictionary to create users This iteration can be done with using with_dict statement, let us see how. Edit group_vars/all file from the parent directory and define a dictionary of systems users to be managed users: admin: uid: 5001 shell: /bin/bash home: /home/admin state: present dojo: state: absent Update the systems task to iterate over this dictionary file: roles/systems/tasks/main.yml - name: create systems users user: name: \"{{ item.key }}\" uid: \"{{ item.value.uid }}\" shell: \"{{ item.value.shell }}\" home: \"{{ item.value.home }}\" state: \"{{ item.value.state }}\" with_dict: \"{{ users }}\" Execute the app playbook to verify the output ansible-playbook app.yml Troubleshooting : Setting defaults The above playbook run fails as you have not defined all the fields for user dojo as part of the dictionary. You could either define it as part of vars, or better set defaults while invoking the vars, so that ansible automatically falls back to it. file: roles/systems/tasks/main.yml - name: create systems users user: name: \"{{ item.key }}\" uid: \"{{ item.value.uid | default('none') }}\" shell: \"{{ item.value.shell | default('none') }}\" home: \"{{ item.value.home | default('none') }}\" state: \"{{ item.value.state | default('none') }}\" with_dict: \"{{ users }}\" Apply and validate ansible-playbook app.yml Refactoring apache playbook to add support for Ubuntu Conditionals structures allow Ansible to choose an alternate path. Ansible does this by using when statements When statement becomes helpful, when you will want to skip a particular step on a particular host Adding app3 Now lets update the inventory to add app3 file: environments/prod [app] app1 app2 app3 ansible_user=devops ansible_ssh_pass=codespaces update package cache on app3 ansible app3 -m ping ansible app3 -b -a \"apt-get update\" Selectively calling install tasks based on platform Current configuration tasks that we have written is compatible with RedHat platform. It may fail on others. Lets selectively call it based on the platform family. Edit roles/apache/tasks/main.yml , - import_tasks: config.yml when: ansible_os_family == 'RedHat' This will include config.yml only if the OS family is Redhat, otherwise it will skip the installation playbook Apache role that we have developed supports only RedHat based systems at the moment. To add support for ubuntu (app2), we must handle platform specific differences. e.g. RedHat Debian Package Name httpd apache2 Service Name httpd apache2 OS specific configurations can be defined by creating role vars and by including those in tasks. file: roles/apache/vars/RedHat.yml --- apache: package: httpd service: name: httpd state: started file: roles/apache/vars/Debian.yml --- apache: package: apache2 service: name: apache2 state: started Lets now selectively include those var files from tasks/main.yml . Also selectively call configurations. file: role/apache/tasks/main.yml --- # tasks file for apache - include_vars: \"{{ ansible_os_family }}.yml\" - import_tasks: install.yml - import_tasks: service.yml - import_tasks: config.yml when: ansible_os_family == 'RedHat' Update tasks and handlers to install and start the correct service tasks/install.yml --- - name: Install Apache... package: name: \"{{ apache.package }}\" state: latest tasks/service.yml --- - name: Starting Apache... service: name: \"{{ apache.service.name }}\" state: \"{{ apache.service.state }}\" handlers/main.yml --- # handlers file for apache - name: Restart apache service service: name: \"{{ apache.service.name }}\" state: restarted You also need to make sure systems role to use package instead of yum module. apply playbook ansible-playbook app.yml Selective execution by using tags What all can be tagged, * tasks * roles * plays * playbooks Options to ansible-playbook related to tags --list-tags --list-tasks --tags= --skip-tags= Tag patterns app 'all:!web' 'lb:db' Lets tag the tasks file: roles/apache/tasks/install.yml --- - name: Install Apache... package: name: \"{{ apache.package }}\" state: latest tags: - apache - install file: roles/apache/tasks/service.yml --- - name: Starting Apache... service: name: \"{{ apache.service.name }}\" state: \"{{ apache.service.state }}\" tags: - apache - service file: roles/apache/tasks/config.yml --- - name: copy apache config copy: src: httpd.conf dest: /etc/httpd.conf owner: root group: root mode: 0644 notify: Restart apache service tags: - apache - config Lets tag the roles and plays too, file: app.yml --- - hosts: app become: true vars: fav: fruit: mango roles: - { role: apache, tags: www } - { role: php, tags: [ 'www', 'php' ] } - { role: frontend, tags: devopsdemo } tags: - frontend and finally the playbooks, file: site.yml --- # This is a sitewide playbook # filename: site.yml - import_playbook: lb.yml tags: lb - import_playbook: app.yml tags: app - import_playbook: db.yml tags: db Now lets influence the tasks execution using tags, ansible-playbook site.yml --list-tags ansible-playbook site.yml --list-tasks ansible-playbook app.yml --tags=php ansible-playbook app.yml --tags='install:config' ansible-playbook site.yml --tags=frontend ansible-playbook app.yml --skip-tags=devopsdemo ansible-playbook site.yml --tags='all:!db:!lb' Adding conditionals in Jinja2 templates Put the following content in roles/frontend/templates/config.ini.j2 [prefs] {% if fav.color is defined %} color = {{ fav['color'] }} {% endif %} {% if fav.fruit is defined %} fruit = {{ fav['fruit'] }} {% endif %} {% if fav.car is defined %} car = {{ fav['car'] }} {% endif %} {% if fav.laptop is defined %} laptop = {{ fav['laptop'] }} {% endif %} In case if the var is not defined, it will not add the config to this file. ansible-playbook site.yml Exercises Define dictionary of properties for a new user in group_vars/prod. Observe if it gets created automatically. Define a hash/dictionary of apache virtual hosts to be created, and create a template which would iterate over that dictionary and create vhost configurations. You would additionally have to create a task to create the vhost configs. Learn about what else you could loop over, as well as how to do so by reading this document http://docs.ansible.com/ansible/playbooks_loops.html#id12","title":"Controlling execution flow with conditionals, iterators and tags"},{"location":"control_structures/#control-structures","text":"In this chapter, we will learn about the aspects of ansible that can change the execution flow. This includes, Iterators/loops Conditionals Tags Conditional inclusions","title":"Control Structures"},{"location":"control_structures/#refactoring-systems-playbook","text":"","title":"Refactoring systems playbook"},{"location":"control_structures/#iterating-over-a-list-of-items-to-install-packages","text":"Create a list of packages Let us create the following list of packages in base role. Edit group_vars/prod.yml and put systems: packages: - ntp - tree - vim Also edit roles/systems/tasks/main.yml to iterate over this list of items and install packages - name: install common systems packages package: name: \"{{ item }}\" state: installed with_items: - \"{{ systems.packages }}\" apply ansible-playbook app.yml","title":"Iterating over a list of items to install packages"},{"location":"control_structures/#iterating-over-a-hash-tabledictionary-to-create-users","text":"This iteration can be done with using with_dict statement, let us see how. Edit group_vars/all file from the parent directory and define a dictionary of systems users to be managed users: admin: uid: 5001 shell: /bin/bash home: /home/admin state: present dojo: state: absent Update the systems task to iterate over this dictionary file: roles/systems/tasks/main.yml - name: create systems users user: name: \"{{ item.key }}\" uid: \"{{ item.value.uid }}\" shell: \"{{ item.value.shell }}\" home: \"{{ item.value.home }}\" state: \"{{ item.value.state }}\" with_dict: \"{{ users }}\" Execute the app playbook to verify the output ansible-playbook app.yml","title":"Iterating over a hash table/dictionary to create users"},{"location":"control_structures/#troubleshooting-setting-defaults","text":"The above playbook run fails as you have not defined all the fields for user dojo as part of the dictionary. You could either define it as part of vars, or better set defaults while invoking the vars, so that ansible automatically falls back to it. file: roles/systems/tasks/main.yml - name: create systems users user: name: \"{{ item.key }}\" uid: \"{{ item.value.uid | default('none') }}\" shell: \"{{ item.value.shell | default('none') }}\" home: \"{{ item.value.home | default('none') }}\" state: \"{{ item.value.state | default('none') }}\" with_dict: \"{{ users }}\" Apply and validate ansible-playbook app.yml","title":"Troubleshooting : Setting defaults"},{"location":"control_structures/#refactoring-apache-playbook-to-add-support-for-ubuntu","text":"Conditionals structures allow Ansible to choose an alternate path. Ansible does this by using when statements When statement becomes helpful, when you will want to skip a particular step on a particular host","title":"Refactoring apache playbook to add support for Ubuntu"},{"location":"control_structures/#adding-app3","text":"Now lets update the inventory to add app3 file: environments/prod [app] app1 app2 app3 ansible_user=devops ansible_ssh_pass=codespaces update package cache on app3 ansible app3 -m ping ansible app3 -b -a \"apt-get update\"","title":"Adding app3"},{"location":"control_structures/#selectively-calling-install-tasks-based-on-platform","text":"Current configuration tasks that we have written is compatible with RedHat platform. It may fail on others. Lets selectively call it based on the platform family. Edit roles/apache/tasks/main.yml , - import_tasks: config.yml when: ansible_os_family == 'RedHat' This will include config.yml only if the OS family is Redhat, otherwise it will skip the installation playbook Apache role that we have developed supports only RedHat based systems at the moment. To add support for ubuntu (app2), we must handle platform specific differences. e.g. RedHat Debian Package Name httpd apache2 Service Name httpd apache2 OS specific configurations can be defined by creating role vars and by including those in tasks. file: roles/apache/vars/RedHat.yml --- apache: package: httpd service: name: httpd state: started file: roles/apache/vars/Debian.yml --- apache: package: apache2 service: name: apache2 state: started Lets now selectively include those var files from tasks/main.yml . Also selectively call configurations. file: role/apache/tasks/main.yml --- # tasks file for apache - include_vars: \"{{ ansible_os_family }}.yml\" - import_tasks: install.yml - import_tasks: service.yml - import_tasks: config.yml when: ansible_os_family == 'RedHat' Update tasks and handlers to install and start the correct service tasks/install.yml --- - name: Install Apache... package: name: \"{{ apache.package }}\" state: latest tasks/service.yml --- - name: Starting Apache... service: name: \"{{ apache.service.name }}\" state: \"{{ apache.service.state }}\" handlers/main.yml --- # handlers file for apache - name: Restart apache service service: name: \"{{ apache.service.name }}\" state: restarted You also need to make sure systems role to use package instead of yum module. apply playbook ansible-playbook app.yml","title":"Selectively calling install tasks based on platform"},{"location":"control_structures/#selective-execution-by-using-tags","text":"What all can be tagged, * tasks * roles * plays * playbooks Options to ansible-playbook related to tags --list-tags --list-tasks --tags= --skip-tags= Tag patterns app 'all:!web' 'lb:db' Lets tag the tasks file: roles/apache/tasks/install.yml --- - name: Install Apache... package: name: \"{{ apache.package }}\" state: latest tags: - apache - install file: roles/apache/tasks/service.yml --- - name: Starting Apache... service: name: \"{{ apache.service.name }}\" state: \"{{ apache.service.state }}\" tags: - apache - service file: roles/apache/tasks/config.yml --- - name: copy apache config copy: src: httpd.conf dest: /etc/httpd.conf owner: root group: root mode: 0644 notify: Restart apache service tags: - apache - config Lets tag the roles and plays too, file: app.yml --- - hosts: app become: true vars: fav: fruit: mango roles: - { role: apache, tags: www } - { role: php, tags: [ 'www', 'php' ] } - { role: frontend, tags: devopsdemo } tags: - frontend and finally the playbooks, file: site.yml --- # This is a sitewide playbook # filename: site.yml - import_playbook: lb.yml tags: lb - import_playbook: app.yml tags: app - import_playbook: db.yml tags: db Now lets influence the tasks execution using tags, ansible-playbook site.yml --list-tags ansible-playbook site.yml --list-tasks ansible-playbook app.yml --tags=php ansible-playbook app.yml --tags='install:config' ansible-playbook site.yml --tags=frontend ansible-playbook app.yml --skip-tags=devopsdemo ansible-playbook site.yml --tags='all:!db:!lb'","title":"Selective execution by using tags"},{"location":"control_structures/#adding-conditionals-in-jinja2-templates","text":"Put the following content in roles/frontend/templates/config.ini.j2 [prefs] {% if fav.color is defined %} color = {{ fav['color'] }} {% endif %} {% if fav.fruit is defined %} fruit = {{ fav['fruit'] }} {% endif %} {% if fav.car is defined %} car = {{ fav['car'] }} {% endif %} {% if fav.laptop is defined %} laptop = {{ fav['laptop'] }} {% endif %} In case if the var is not defined, it will not add the config to this file. ansible-playbook site.yml","title":"Adding conditionals in Jinja2 templates"},{"location":"control_structures/#exercises","text":"Define dictionary of properties for a new user in group_vars/prod. Observe if it gets created automatically. Define a hash/dictionary of apache virtual hosts to be created, and create a template which would iterate over that dictionary and create vhost configurations. You would additionally have to create a task to create the vhost configs. Learn about what else you could loop over, as well as how to do so by reading this document http://docs.ansible.com/ansible/playbooks_loops.html#id12","title":"Exercises"},{"location":"custom_modules/","text":"Creating a custiom Modules Writing module with bash mkdir library touch library/mymodule file: library/mymodule #!/bin/bash display=\"This is a simple bash module..\" echo -e \"{\\\"message\\\":\\\"\"$display\"\\\"}\" file: custom_modules.yml --- - hosts: local sudo: yes tasks: - name: test custom module mymodule: register: uptime - debug: var=uptime Test ansible-playbook custom_module.yml Accepting module options file: custom_modules.yml - name: check version printversion: app: java appv: 3.4 register: printversion - debug: var=printversion file: library/printversion #!/bin/bash # # This script accepts two inputs # 1. app # 2. appv # and prints it as a message changed=\"false\" source $1 display=\"Received app $app with version as $appv\" if [ \"$app\" == \"python\" ]; then changed=\"true\" fi printf '{\"changed\": %s, \"msg\": \"%s\"}' \"$changed\" \"$display\" exit 0 Test ansible-playbook custom_module.yml Trying out sample python module cd library wget -c https://gist.githubusercontent.com/initcron/88049b4fc3cbf4c53d17405efdd3a720/raw/fd2a4bccbe8fa895e3f6a6b517ec74abd1844df5/my_new_test_module file: custom_modules.yml - name: run the new module my_new_test_module: name: 'hello' new: true register: testout - name: dump test output debug: msg: '{{ testout }}' Test ansible-playbook custom_module.yml","title":"Custom Module"},{"location":"custom_modules/#creating-a-custiom-modules","text":"","title":"Creating a custiom Modules"},{"location":"custom_modules/#writing-module-with-bash","text":"mkdir library touch library/mymodule file: library/mymodule #!/bin/bash display=\"This is a simple bash module..\" echo -e \"{\\\"message\\\":\\\"\"$display\"\\\"}\" file: custom_modules.yml --- - hosts: local sudo: yes tasks: - name: test custom module mymodule: register: uptime - debug: var=uptime Test ansible-playbook custom_module.yml","title":"Writing module with bash"},{"location":"custom_modules/#accepting-module-options","text":"file: custom_modules.yml - name: check version printversion: app: java appv: 3.4 register: printversion - debug: var=printversion file: library/printversion #!/bin/bash # # This script accepts two inputs # 1. app # 2. appv # and prints it as a message changed=\"false\" source $1 display=\"Received app $app with version as $appv\" if [ \"$app\" == \"python\" ]; then changed=\"true\" fi printf '{\"changed\": %s, \"msg\": \"%s\"}' \"$changed\" \"$display\" exit 0 Test ansible-playbook custom_module.yml","title":"Accepting module options"},{"location":"custom_modules/#trying-out-sample-python-module","text":"cd library wget -c https://gist.githubusercontent.com/initcron/88049b4fc3cbf4c53d17405efdd3a720/raw/fd2a4bccbe8fa895e3f6a6b517ec74abd1844df5/my_new_test_module file: custom_modules.yml - name: run the new module my_new_test_module: name: 'hello' new: true register: testout - name: dump test output debug: msg: '{{ testout }}' Test ansible-playbook custom_module.yml","title":"Trying out sample python module"},{"location":"dynamic_inventory/","text":"Using dynamic inventory with ec2 Download the script to setup dynamic inventory wget -c https://raw.githubusercontent.com/ansible/ansible/devel/contrib/inventory/ec2.py create ec2.ini with crdentials to connect to aws. Best practice : its recommended you create a read only user and use the iam keys for the same with ansible. For dynamic inventory, Ansible does need any additional access to make changes. Its a recommended security practice. sample ec2.ini [profile staging] export AWS_ACCESS_KEY_ID='AKJKHKSDHFSJHJD73NEQ2Q' export AWS_SECRET_ACCESS_KEY='aUy56Ksmw2bD/Aepmsdge3KsasnMSJIHls209NZpTc7' its also recommeded you store this file somewhere securely with least privileges e.g. mv ec2.ini ~/.ec2.ini chmod 400 ~/.ec2.ini Set the path to ini file export EC2_INI_PATH=~/.ec2.ini Create a local ansible configuration [defaults] remote_user = ubuntu inventory = ec2.py retry_files_save_path = /tmp host_key_checking = False log_path=ansible.log Now test the dynamic inventory script examples (update as per your profile and instance configs) ./ec2.py --list ./ec2.py --profile demo /ec2.py --host 38.105.83.147 This should connect to aws, fetch information and display groups dynamically fetched. You should now be ready to connect to the ec2 servers e.g. ansible all --list-hosts ansible ec2 --list-hosts ansible ec2 -m ping ansible tag_env_demo -m ping Writing your own dynmaic inventory References: http://docs.ansible.com/ansible/latest/intro_dynamic_inventory.html http://docs.ansible.com/ansible/latest/dev_guide/developing_inventory.html https://www.jeffgeerling.com/blog/creating-custom-dynamic-inventories-ansible --list --host","title":"Dynamic Inventory"},{"location":"dynamic_inventory/#using-dynamic-inventory-with-ec2","text":"Download the script to setup dynamic inventory wget -c https://raw.githubusercontent.com/ansible/ansible/devel/contrib/inventory/ec2.py create ec2.ini with crdentials to connect to aws. Best practice : its recommended you create a read only user and use the iam keys for the same with ansible. For dynamic inventory, Ansible does need any additional access to make changes. Its a recommended security practice. sample ec2.ini [profile staging] export AWS_ACCESS_KEY_ID='AKJKHKSDHFSJHJD73NEQ2Q' export AWS_SECRET_ACCESS_KEY='aUy56Ksmw2bD/Aepmsdge3KsasnMSJIHls209NZpTc7' its also recommeded you store this file somewhere securely with least privileges e.g. mv ec2.ini ~/.ec2.ini chmod 400 ~/.ec2.ini Set the path to ini file export EC2_INI_PATH=~/.ec2.ini Create a local ansible configuration [defaults] remote_user = ubuntu inventory = ec2.py retry_files_save_path = /tmp host_key_checking = False log_path=ansible.log Now test the dynamic inventory script examples (update as per your profile and instance configs) ./ec2.py --list ./ec2.py --profile demo /ec2.py --host 38.105.83.147 This should connect to aws, fetch information and display groups dynamically fetched. You should now be ready to connect to the ec2 servers e.g. ansible all --list-hosts ansible ec2 --list-hosts ansible ec2 -m ping ansible tag_env_demo -m ping","title":"Using dynamic inventory with ec2"},{"location":"dynamic_inventory/#writing-your-own-dynmaic-inventory","text":"References: http://docs.ansible.com/ansible/latest/intro_dynamic_inventory.html http://docs.ansible.com/ansible/latest/dev_guide/developing_inventory.html https://www.jeffgeerling.com/blog/creating-custom-dynamic-inventories-ansible --list --host","title":"Writing your own dynmaic inventory"},{"location":"galaxy/","text":"Setting up loadbalancer with a galaxy role With this lab, you are going to setup HAProxy, a lightweight open source load balancer using a role available in Ansible Galaxy. Browse to Ansible Galaxy to browse or search for the roles available and understand how Galaxy works. Then proceed with the steps below to setup haproxy. Fetch a role from galaxy as, cd chap8 ansible-galaxy install geerlingguy.haproxy Create a new playbook in the top level dir with name lb.yml - hosts: lb become: yes roles: - { role: geerlingguy.haproxy } Also add the custom vars that you would like to override and customize as per your setup. e.g. file: group_vars/prod.yml haproxy_backend_httpchk: '' haproxy_backend_servers: - name: app1 address: 192.168.61.12:80 - name: app2 address: 192.168.61.13:80 And apply the playbook ansible-playbook lb.yml To validate, load the haproxy configurations now for load balancer which is now running on port 80 on your host. http://IPADDRESS/app You could also verify by checking the haproxy configs as ssh devops@lb cat /etc/haproxy/haproxy.cfg You should see the following block configured in haproxy.cfg backend habackend mode http balance roundrobin option forwardfor cookie SERVERID insert indirect server app1 192.168.61.12:80 cookie app1 check server app2 192.168.61.13:80 cookie app2 check Which confirms that haproxy has picked up the web servers and load balancing traffic across it. Exercises Nano Project: Setup MySQL Database Now that you have configured load balancer along with the app servers, its time to setup database backend. And you could leverage ansible galaxy instead of writing all the code from scratch. Once you select and install role, create a playbook that would apply to db group from inventory. In addition to setting up the mysql server, you would create * database: devopsdemo * user: devops * password: password-of-your-choice * root password: password-of-your-choice and set grant permissions so that the devops user owns devopsdemo db.","title":"Setting up Load Balancer with Ansible Galaxy"},{"location":"galaxy/#setting-up-loadbalancer-with-a-galaxy-role","text":"With this lab, you are going to setup HAProxy, a lightweight open source load balancer using a role available in Ansible Galaxy. Browse to Ansible Galaxy to browse or search for the roles available and understand how Galaxy works. Then proceed with the steps below to setup haproxy. Fetch a role from galaxy as, cd chap8 ansible-galaxy install geerlingguy.haproxy Create a new playbook in the top level dir with name lb.yml - hosts: lb become: yes roles: - { role: geerlingguy.haproxy } Also add the custom vars that you would like to override and customize as per your setup. e.g. file: group_vars/prod.yml haproxy_backend_httpchk: '' haproxy_backend_servers: - name: app1 address: 192.168.61.12:80 - name: app2 address: 192.168.61.13:80 And apply the playbook ansible-playbook lb.yml To validate, load the haproxy configurations now for load balancer which is now running on port 80 on your host. http://IPADDRESS/app You could also verify by checking the haproxy configs as ssh devops@lb cat /etc/haproxy/haproxy.cfg You should see the following block configured in haproxy.cfg backend habackend mode http balance roundrobin option forwardfor cookie SERVERID insert indirect server app1 192.168.61.12:80 cookie app1 check server app2 192.168.61.13:80 cookie app2 check Which confirms that haproxy has picked up the web servers and load balancing traffic across it.","title":"Setting up loadbalancer with a galaxy role"},{"location":"galaxy/#exercises","text":"","title":"Exercises"},{"location":"galaxy/#nano-project-setup-mysql-database","text":"Now that you have configured load balancer along with the app servers, its time to setup database backend. And you could leverage ansible galaxy instead of writing all the code from scratch. Once you select and install role, create a playbook that would apply to db group from inventory. In addition to setting up the mysql server, you would create * database: devopsdemo * user: devops * password: password-of-your-choice * root password: password-of-your-choice and set grant permissions so that the devops user owns devopsdemo db.","title":"Nano Project: Setup MySQL Database"},{"location":"intro/","text":"Introduction to Ansible","title":"Introduction to Ansible"},{"location":"intro/#introduction-to-ansible","text":"","title":"Introduction to Ansible"},{"location":"magicvars_envs/","text":"Magic Variables for Service Discovery, Multiple Environments file: ansible.cfg fact_caching = yaml fact_caching_connection = /tmp/facts file: roles/geerlingguy.haproxy/templates/haproxy.cfg.j2 {% for host in groups['app'] %} server {{ hostvars[host]['ansible_hostname'] }} {{ hostvars[host]['ansible_eth0']['ipv4']['address'] }}:80 cookie {{ hostvars[host]['ansible_hostname'] }} check {% endfor %} Create staging env production/staging [app] app2 [db] app2 [staging:children] app db file: group_vars/all.yml --- users: admin: uid: 5001 shell: /bin/bash home: /home/admin state: present dojo: state: absent systems: packages: - ntp - tree - vim file: group_vars/staging.yml --- app: version: 1.5 env: staging fav: color: blue fruit: watermelon dbconn: host: 127.0.0.1 user: devops pass: dfkl8d6msoYc0 db: devopsdemo mysql_root_password: dfdvdHkst0ks72sY mysql_databases: - name: devopsdemo encoding: latin1 collation: latin1_general_ci mysql_users: - name: devops host: \"%\" password: dfkl8d6msoYc0 priv: \"devopsdemo.*:ALL\" Cleaning up cleanup.yml --- - name: cleanup database server hosts: db become: true tasks: - name: stop mysql service service: name: mysqld state: stopped - name: uninstall mysql related packages package: name: \"{{ item }}\" state: absent with_items: - mysql-server - mysql","title":"Auto discovery and multi environments"},{"location":"magicvars_envs/#magic-variables-for-service-discovery-multiple-environments","text":"file: ansible.cfg fact_caching = yaml fact_caching_connection = /tmp/facts file: roles/geerlingguy.haproxy/templates/haproxy.cfg.j2 {% for host in groups['app'] %} server {{ hostvars[host]['ansible_hostname'] }} {{ hostvars[host]['ansible_eth0']['ipv4']['address'] }}:80 cookie {{ hostvars[host]['ansible_hostname'] }} check {% endfor %}","title":"Magic Variables for Service Discovery, Multiple Environments"},{"location":"magicvars_envs/#create-staging-env","text":"production/staging [app] app2 [db] app2 [staging:children] app db file: group_vars/all.yml --- users: admin: uid: 5001 shell: /bin/bash home: /home/admin state: present dojo: state: absent systems: packages: - ntp - tree - vim file: group_vars/staging.yml --- app: version: 1.5 env: staging fav: color: blue fruit: watermelon dbconn: host: 127.0.0.1 user: devops pass: dfkl8d6msoYc0 db: devopsdemo mysql_root_password: dfdvdHkst0ks72sY mysql_databases: - name: devopsdemo encoding: latin1 collation: latin1_general_ci mysql_users: - name: devops host: \"%\" password: dfkl8d6msoYc0 priv: \"devopsdemo.*:ALL\"","title":"Create staging env"},{"location":"magicvars_envs/#cleaning-up","text":"cleanup.yml --- - name: cleanup database server hosts: db become: true tasks: - name: stop mysql service service: name: mysqld state: stopped - name: uninstall mysql related packages package: name: \"{{ item }}\" state: absent with_items: - mysql-server - mysql","title":"Cleaning up"},{"location":"markdown_cheatsheet/","text":"{pagebreak} Part Section Sub Section Sub Sub Section Sub Sub Sub Section This is the first para This is the 2nd para separated by a line This is the 3rd para separated by 2 spaces at the end of line before c> This is a centered text italic bold bold-italic _underlined _ Numbered list item 1 Numbered list item 2 test para between list item 4 indents, blank like after prev item, num seq continues Numbered list item 3 Bullet list item 1 Bullet list item 2 Sub Item 2.1 Sub Sub item 2.1.1 Bullet list item 3 Header : description of the header This is a Block Quote Block Quote gets indented block quote inside a block quote Text Blocks Asides A> ## This is an aside A> A> This gets printed in a block Warnings W> ## This is a Warning W> W> Always wear the seat belt Tips T> ## This is a tip T> T> Bet for number 5 on that table Errors E> ## This prints an error E> E> Oops ! You just barged into ladies toilet Information I> ## This is to print info I> I> For your eyes only Questions Q> ## This prints questions Q> Q> What came first, chicken or the engg? Discussions D> ## This is for Discussions D> D> Lets talk about Life of Pie Exercises X> ## This is for exercises X> X> 10 mins on treadmill X> followed by two sets of pushups Writing Code Method 1 : 4 space indentation echo \"this starts with 4 indents\" ls -l cat /etc/issue uptime Method 2: 8 tildes echo \"this has 8 tildes on the top and bottom\" echo \"8 tildes is a best practice, but any no. will do \" uptime ls -l cat /etc/issue Method 3 : include code from file <<(code/sample_code.sh) << sample_code_with_title Method 4 : lp-code style {title=\"Listing \", lang=html, linenos=off} echo \"this is autocompleted by leanpub plugin for atom\" uptime df -h ls -l Method 5: back ticks `` echo \"this is a short code snippet\" Footnotes This is a text para and I am writing a footnote[^tag1] here Later on I add the footnote as [^tag1]: description about the footnote. Should contain blank line before and after Crosslinks This is a cross link to {##Sub Section} Table header1 header2 r1-c1 r1-c2 r2-c1 r2-c2 r3-c1 r3-c2 Header One Header Two Item One Item Two","title":"Markdown cheatsheet"},{"location":"markdown_cheatsheet/#part","text":"","title":"Part"},{"location":"markdown_cheatsheet/#section","text":"","title":"Section"},{"location":"markdown_cheatsheet/#sub-section","text":"","title":"Sub Section"},{"location":"markdown_cheatsheet/#sub-sub-section","text":"","title":"Sub Sub Section"},{"location":"markdown_cheatsheet/#sub-sub-sub-section","text":"This is the first para This is the 2nd para separated by a line This is the 3rd para separated by 2 spaces at the end of line before c> This is a centered text italic bold bold-italic _underlined _ Numbered list item 1 Numbered list item 2 test para between list item 4 indents, blank like after prev item, num seq continues Numbered list item 3 Bullet list item 1 Bullet list item 2 Sub Item 2.1 Sub Sub item 2.1.1 Bullet list item 3 Header : description of the header This is a Block Quote Block Quote gets indented block quote inside a block quote Text Blocks Asides A> ## This is an aside A> A> This gets printed in a block Warnings W> ## This is a Warning W> W> Always wear the seat belt Tips T> ## This is a tip T> T> Bet for number 5 on that table Errors E> ## This prints an error E> E> Oops ! You just barged into ladies toilet Information I> ## This is to print info I> I> For your eyes only Questions Q> ## This prints questions Q> Q> What came first, chicken or the engg? Discussions D> ## This is for Discussions D> D> Lets talk about Life of Pie Exercises X> ## This is for exercises X> X> 10 mins on treadmill X> followed by two sets of pushups Writing Code Method 1 : 4 space indentation echo \"this starts with 4 indents\" ls -l cat /etc/issue uptime Method 2: 8 tildes echo \"this has 8 tildes on the top and bottom\" echo \"8 tildes is a best practice, but any no. will do \" uptime ls -l cat /etc/issue Method 3 : include code from file <<(code/sample_code.sh) << sample_code_with_title Method 4 : lp-code style {title=\"Listing \", lang=html, linenos=off} echo \"this is autocompleted by leanpub plugin for atom\" uptime df -h ls -l Method 5: back ticks `` echo \"this is a short code snippet\" Footnotes This is a text para and I am writing a footnote[^tag1] here Later on I add the footnote as [^tag1]: description about the footnote. Should contain blank line before and after Crosslinks This is a cross link to {##Sub Section} Table header1 header2 r1-c1 r1-c2 r2-c1 r2-c2 r3-c1 r3-c2 Header One Header Two Item One Item Two","title":"Sub Sub Sub Section"},{"location":"modules/","text":"Modules Topics Included Desired State Configurations Invoking Modules Using Common Modules Command Modules and Idempotence Desired State Configuration Desired State :- Once You decribe WHAT you want using desired state configurations you need not to worry about How the state is acheived, whether to take an action on which action to take It's Ansible's Job user <---------- Entity name = XYZ <----------Properties State = Present <---------- Desired State uid = 5001 <---------- Properties group = admins <---------- Properties Module Categories System Cloud Networking Utilities Files Database Inventory Messaging Remote management Module Types Core Extras Core :- Maintained by ansible team Will always be shipped with ansible Extras :- Maintained by community Currently shipped with ansible May be shipped separately in future Invoking Modules Usage :- Modules are typically executed as a part of ansible command. ansible app -m yum -s -a \"name=ntp state installed\" * -m yum ---------> Module name * name=ntp ---------> key=value * state installed ---------> arguments Modules can also be called while writing tasks in Playbook using YAML - name : install ntp package yum : > name: ntp state: present **Output** app1 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } #### FINDING INFO **ansible-doc** :- This utility helps you find list of modules, how to use those along with example snippets. ansible-doc --help ansible-doc --list | head ansible-doc user ansible-doc -s user ``` Using Common Modules Common Modules :- Packages yum apt gem pip Files copy fetch template System user group cron mount ping Utilities debug assert wait_for Commands command shell expect Command Modules Command :- Does not use Shell Does not have access to env This > < | ; & operators will not work Secure and recommended Shell :- Invokes /bin/sh Has access to env, variables etc This > < | ; & operators will work Use selectively","title":"Modules"},{"location":"modules/#modules","text":"","title":"Modules"},{"location":"modules/#topics-included","text":"Desired State Configurations Invoking Modules Using Common Modules Command Modules and Idempotence","title":"Topics Included"},{"location":"modules/#desired-state-configuration","text":"Desired State :- Once You decribe WHAT you want using desired state configurations you need not to worry about How the state is acheived, whether to take an action on which action to take It's Ansible's Job user <---------- Entity name = XYZ <----------Properties State = Present <---------- Desired State uid = 5001 <---------- Properties group = admins <---------- Properties","title":"Desired State Configuration"},{"location":"modules/#module-categories","text":"System Cloud Networking Utilities Files Database Inventory Messaging Remote management","title":"Module Categories"},{"location":"modules/#module-types","text":"Core Extras","title":"Module Types"},{"location":"modules/#core-","text":"Maintained by ansible team Will always be shipped with ansible","title":"Core :-"},{"location":"modules/#extras-","text":"Maintained by community Currently shipped with ansible May be shipped separately in future","title":"Extras :-"},{"location":"modules/#invoking-modules","text":"Usage :- Modules are typically executed as a part of ansible command. ansible app -m yum -s -a \"name=ntp state installed\" * -m yum ---------> Module name * name=ntp ---------> key=value * state installed ---------> arguments Modules can also be called while writing tasks in Playbook using YAML - name : install ntp package yum : > name: ntp state: present **Output** app1 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } #### FINDING INFO **ansible-doc** :- This utility helps you find list of modules, how to use those along with example snippets. ansible-doc --help ansible-doc --list | head ansible-doc user ansible-doc -s user ```","title":"Invoking Modules"},{"location":"modules/#using-common-modules","text":"","title":"Using Common Modules"},{"location":"modules/#common-modules-","text":"Packages yum apt gem pip Files copy fetch template System user group cron mount ping Utilities debug assert wait_for Commands command shell expect","title":"Common Modules :-"},{"location":"modules/#command-modules","text":"Command :- Does not use Shell Does not have access to env This > < | ; & operators will not work Secure and recommended Shell :- Invokes /bin/sh Has access to env, variables etc This > < | ; & operators will work Use selectively","title":"Command Modules"},{"location":"playbooks/","text":"Writing Playbook for Base System Configurations In this tutorial we are going to create a simple playbook to add system users, install and start ntp service and some basic utilities. Problem Statement You have to create a playbook to configure all linux systems which will create a admin user with uid 5001 remove user dojo install tree utility install ntp on all systems which belong to prod group in the inventory To prepare for this chapter, lets switch the directory in the workspace, From the workspace, change to chap5 cd chap5 Edit environments/prod if required and comment the hosts which are absent. Create a new file with name systems.yml and add the following content to it --- - name: Base Configurations for ALL hosts hosts: all become: true tasks: - name: create admin user user: name: admin state: present uid: 5001 - name: remove dojo user: name: dojo state: absent - name: install tree yum: name: tree state: present - name: install ntp yum: name: ntp state: present Validating Syntax Option 1 : Using --syntax-check option with ansible-playbook ansible-playbook systems.yml --syntax-check Exercise: Break the syntax, run playbook with --syntax check again, and learn how it works. Option 2 : Using YAML Linter Online Another way to validate syntax Visit http://www.yamllinter.com Using ansible-playbook utility We will start using ansible-playbook utility to execute playbooks. To learn how to use ansible-playbook execute the following command, ansible-playbook --help [output] Usage: ansible-playbook systems.yml Options: --ask-become-pass ask for privilege escalation password -k, --ask-pass ask for connection password --ask-su-pass ask for su password (deprecated, use become) -K, --ask-sudo-pass ask for sudo password (deprecated, use become) --ask-vault-pass ask for vault password -b, --become run operations with become (nopasswd implied) --become-method=BECOME_METHOD privilege escalation method to use (default=sudo), valid choices: [ sudo | su | pbrun | pfexec | runas | doas ] ....... Dry Run To execute ansible in a check mode, which will simulate tasks on the remote nodes, without actually committing, ansible provides --check or -C option. This can be invoked as , ansible-playbook systems.yml --check or ansible-playbook systems.yml -C Listing Hosts, Tasks and Tags in a Playbook ansible-playbook systems.yml --list-hosts ansible-playbook systems.yml --list-tasks ansible-playbook systems.yml --list-tags Executing Actions with Playbooks To execute the playbook, we are going to execute ansible-playbook comman with playbook YAML file as an argument. Since we have already defined the inventory and configurations, additional options are not necessary at this time. ansible-playbook systems.yml [output] PLAY [Base Configurations for ALL hosts] *************************************** TASK [setup] ******************************************************************* ok: [192.168.61.14] ok: [192.168.61.11] ok: [localhost] ok: [192.168.61.12] ok: [192.168.61.13] TASK [create admin user] ******************************************************* changed: [192.168.61.13] changed: [192.168.61.12] changed: [localhost] changed: [192.168.61.11] changed: [192.168.61.14] TASK [remove dojo] ************************************************************* changed: [192.168.61.14] changed: [localhost] changed: [192.168.61.12] changed: [192.168.61.11] changed: [192.168.61.13] TASK [install tree] ************************************************************ ok: [localhost] ok: [192.168.61.13] ok: [192.168.61.12] ok: [192.168.61.14] ok: [192.168.61.11] TASK [install ntp] ************************************************************* changed: [192.168.61.12] changed: [192.168.61.13] changed: [192.168.61.11] changed: [localhost] changed: [192.168.61.14] Error Handling and Debugging We are now going to add a new task to the playbook that we created. This task would start ntp service on all prod hosts. When you add this task, make sure the indentation is correct. - name: start ntp service service: name: ntp state: started enabled: yes Apply playbook again, check the output ansible-playbook systems.yml [output] TASK [start ntp service] ******************************************************* fatal: [localhost]: FAILED! => {\"changed\": false, \"failed\": true, \"msg\": \"no service or tool found for: ntp\"} fatal: [192.168.61.11]: FAILED! => {\"changed\": false, \"failed\": true, \"msg\": \"no service or tool found for: ntp\"} fatal: [192.168.61.12]: FAILED! => {\"changed\": false, \"failed\": true, \"msg\": \"no service or tool found for: ntp\"} NO MORE HOSTS LEFT ************************************************************* to retry, use: --limit @/tmp/playbook.retry PLAY RECAP ********************************************************************* 192.168.61.11 : ok=5 changed=0 unreachable=0 failed=1 192.168.61.12 : ok=5 changed=0 unreachable=0 failed=1 localhost : ok=5 changed=0 unreachable=0 failed=1 Exercise : There was a intentional error introduced in the code. Identify the error from the log message above, correct it and run the playbook again. This time you should run it only on the failed hosts by limiting with the retry file mentioned above (e.g. --limit @/tmp/playbook.retry ) Debugging Technique : Step By Step Execution Ansible provides a way to execute tasks step by step, asking you whether to run or skip each task. This can be useful while debugging issues. ansible-playbook systems.yml --step [Output] root@control:/workspace/chap5# ansible-playbook systems.yml --step PLAY [Base Configurations for ALL hosts] *************************************** Perform task: TASK: setup (N)o/(y)es/(c)ontinue: y TASK [setup] ******************************************************************* y ok: [app1] ok: [db] ok: [app2] ok: [lb] Perform task: TASK: create admin user (N)o/(y)es/(c)ontinue: TASK [create admin user] ******************************************************* yok: [app2] ok: [app1] ok: [db] ok: [lb] Perform task: TASK: install tree (N)o/(y)es/(c)ontinue: y TASK [install tree] ************************************************************ ok: [app2] ok: [lb] ok: [app1] ok: [db] Adding Additional Play Problem Statement: You have to add a new play to configure the following only on the app servers create a deploy user with uid 5003 install git on all app servers in the inventory Lets add a second play specific to app servers. Add the following block of code in systems.yml file and save - name: App Server Configurations hosts: app become: true tasks: - name: create deploy user user: name: deploy state: present uid: 5003 - name: install git yum: name: git state: present Run the playbook again... ansible-playbook systems.yml ....... PLAY [App Server Configurations] *********************************************** TASK [setup] ******************************************************************* ok: [192.168.61.13] ok: [192.168.61.12] TASK [create app user] ********************************************************* changed: [192.168.61.12] changed: [192.168.61.13] TASK [install git] ************************************************************* ok: [192.168.61.13] ok: [192.168.61.12] PLAY RECAP ********************************************************************* 192.168.61.11 : ok=6 changed=0 unreachable=0 failed=0 192.168.61.12 : ok=9 changed=1 unreachable=0 failed=0 192.168.61.13 : ok=9 changed=1 unreachable=0 failed=0 192.168.61.14 : ok=6 changed=0 unreachable=0 failed=0 localhost : ok=6 changed=0 unreachable=0 failed=0 Limiting the execution to a particular group Now run the following command to restrict the playbook execution to app servers ansible-playbook systems.yml --limit app This will give us the following output, plays will be executed only on app servers... PLAY [Base Configurations for ALL hosts] *************************************** TASK [setup] ******************************************************************* ok: [192.168.61.13] ok: [192.168.61.12] ......... TASK [start ntp service] ******************************************************* ok: [192.168.61.12] ok: [192.168.61.13] PLAY [App Server Configurations] *********************************************** ........ TASK [install git] ************************************************************* ok: [192.168.61.12] ok: [192.168.61.13] PLAY RECAP ********************************************************************* 192.168.61.12 : ok=9 changed=0 unreachable=0 failed=0 192.168.61.13 : ok=9 changed=0 unreachable=0 failed=0 Exercises: Nano Project : Create a Playbook with the following specifications, It should apply only on local host (ansible host) Should use become method Should create a user called webadmin with shell as \"/bin/sh\" Should install and start nginx service Should deploy a sample html app into the default web root directory of nginx using ansible's git module. Source repo: https://github.com/schoolofdevops/html-sample-app Deploy Path : /usr/share/nginx/html/app Once deployed, validate the site by visting http://CONTROL_HOST_IP/app Exercise : Disable Facts Gathering Run ansible playbook and observe the output Add the following configuration parameter to ansible.cfg gathering = explicit Launch ansible playbook run again, observe the output and compare it with the previous run.","title":"Writing Playbook for Base System Configurations"},{"location":"playbooks/#writing-playbook-for-base-system-configurations","text":"In this tutorial we are going to create a simple playbook to add system users, install and start ntp service and some basic utilities. Problem Statement You have to create a playbook to configure all linux systems which will create a admin user with uid 5001 remove user dojo install tree utility install ntp on all systems which belong to prod group in the inventory To prepare for this chapter, lets switch the directory in the workspace, From the workspace, change to chap5 cd chap5 Edit environments/prod if required and comment the hosts which are absent. Create a new file with name systems.yml and add the following content to it --- - name: Base Configurations for ALL hosts hosts: all become: true tasks: - name: create admin user user: name: admin state: present uid: 5001 - name: remove dojo user: name: dojo state: absent - name: install tree yum: name: tree state: present - name: install ntp yum: name: ntp state: present","title":"Writing Playbook for Base System Configurations"},{"location":"playbooks/#validating-syntax","text":"Option 1 : Using --syntax-check option with ansible-playbook ansible-playbook systems.yml --syntax-check Exercise: Break the syntax, run playbook with --syntax check again, and learn how it works. Option 2 : Using YAML Linter Online Another way to validate syntax Visit http://www.yamllinter.com","title":"Validating Syntax"},{"location":"playbooks/#using-ansible-playbook-utility","text":"We will start using ansible-playbook utility to execute playbooks. To learn how to use ansible-playbook execute the following command, ansible-playbook --help [output] Usage: ansible-playbook systems.yml Options: --ask-become-pass ask for privilege escalation password -k, --ask-pass ask for connection password --ask-su-pass ask for su password (deprecated, use become) -K, --ask-sudo-pass ask for sudo password (deprecated, use become) --ask-vault-pass ask for vault password -b, --become run operations with become (nopasswd implied) --become-method=BECOME_METHOD privilege escalation method to use (default=sudo), valid choices: [ sudo | su | pbrun | pfexec | runas | doas ] .......","title":"Using ansible-playbook utility"},{"location":"playbooks/#dry-run","text":"To execute ansible in a check mode, which will simulate tasks on the remote nodes, without actually committing, ansible provides --check or -C option. This can be invoked as , ansible-playbook systems.yml --check or ansible-playbook systems.yml -C","title":"Dry Run"},{"location":"playbooks/#listing-hosts-tasks-and-tags-in-a-playbook","text":"ansible-playbook systems.yml --list-hosts ansible-playbook systems.yml --list-tasks ansible-playbook systems.yml --list-tags","title":"Listing Hosts, Tasks and Tags in a Playbook"},{"location":"playbooks/#executing-actions-with-playbooks","text":"To execute the playbook, we are going to execute ansible-playbook comman with playbook YAML file as an argument. Since we have already defined the inventory and configurations, additional options are not necessary at this time. ansible-playbook systems.yml [output] PLAY [Base Configurations for ALL hosts] *************************************** TASK [setup] ******************************************************************* ok: [192.168.61.14] ok: [192.168.61.11] ok: [localhost] ok: [192.168.61.12] ok: [192.168.61.13] TASK [create admin user] ******************************************************* changed: [192.168.61.13] changed: [192.168.61.12] changed: [localhost] changed: [192.168.61.11] changed: [192.168.61.14] TASK [remove dojo] ************************************************************* changed: [192.168.61.14] changed: [localhost] changed: [192.168.61.12] changed: [192.168.61.11] changed: [192.168.61.13] TASK [install tree] ************************************************************ ok: [localhost] ok: [192.168.61.13] ok: [192.168.61.12] ok: [192.168.61.14] ok: [192.168.61.11] TASK [install ntp] ************************************************************* changed: [192.168.61.12] changed: [192.168.61.13] changed: [192.168.61.11] changed: [localhost] changed: [192.168.61.14]","title":"Executing Actions with Playbooks"},{"location":"playbooks/#error-handling-and-debugging","text":"We are now going to add a new task to the playbook that we created. This task would start ntp service on all prod hosts. When you add this task, make sure the indentation is correct. - name: start ntp service service: name: ntp state: started enabled: yes Apply playbook again, check the output ansible-playbook systems.yml [output] TASK [start ntp service] ******************************************************* fatal: [localhost]: FAILED! => {\"changed\": false, \"failed\": true, \"msg\": \"no service or tool found for: ntp\"} fatal: [192.168.61.11]: FAILED! => {\"changed\": false, \"failed\": true, \"msg\": \"no service or tool found for: ntp\"} fatal: [192.168.61.12]: FAILED! => {\"changed\": false, \"failed\": true, \"msg\": \"no service or tool found for: ntp\"} NO MORE HOSTS LEFT ************************************************************* to retry, use: --limit @/tmp/playbook.retry PLAY RECAP ********************************************************************* 192.168.61.11 : ok=5 changed=0 unreachable=0 failed=1 192.168.61.12 : ok=5 changed=0 unreachable=0 failed=1 localhost : ok=5 changed=0 unreachable=0 failed=1 Exercise : There was a intentional error introduced in the code. Identify the error from the log message above, correct it and run the playbook again. This time you should run it only on the failed hosts by limiting with the retry file mentioned above (e.g. --limit @/tmp/playbook.retry )","title":"Error Handling and Debugging"},{"location":"playbooks/#debugging-technique-step-by-step-execution","text":"Ansible provides a way to execute tasks step by step, asking you whether to run or skip each task. This can be useful while debugging issues. ansible-playbook systems.yml --step [Output] root@control:/workspace/chap5# ansible-playbook systems.yml --step PLAY [Base Configurations for ALL hosts] *************************************** Perform task: TASK: setup (N)o/(y)es/(c)ontinue: y TASK [setup] ******************************************************************* y ok: [app1] ok: [db] ok: [app2] ok: [lb] Perform task: TASK: create admin user (N)o/(y)es/(c)ontinue: TASK [create admin user] ******************************************************* yok: [app2] ok: [app1] ok: [db] ok: [lb] Perform task: TASK: install tree (N)o/(y)es/(c)ontinue: y TASK [install tree] ************************************************************ ok: [app2] ok: [lb] ok: [app1] ok: [db]","title":"Debugging Technique : Step By Step Execution"},{"location":"playbooks/#adding-additional-play","text":"Problem Statement: You have to add a new play to configure the following only on the app servers create a deploy user with uid 5003 install git on all app servers in the inventory Lets add a second play specific to app servers. Add the following block of code in systems.yml file and save - name: App Server Configurations hosts: app become: true tasks: - name: create deploy user user: name: deploy state: present uid: 5003 - name: install git yum: name: git state: present Run the playbook again... ansible-playbook systems.yml ....... PLAY [App Server Configurations] *********************************************** TASK [setup] ******************************************************************* ok: [192.168.61.13] ok: [192.168.61.12] TASK [create app user] ********************************************************* changed: [192.168.61.12] changed: [192.168.61.13] TASK [install git] ************************************************************* ok: [192.168.61.13] ok: [192.168.61.12] PLAY RECAP ********************************************************************* 192.168.61.11 : ok=6 changed=0 unreachable=0 failed=0 192.168.61.12 : ok=9 changed=1 unreachable=0 failed=0 192.168.61.13 : ok=9 changed=1 unreachable=0 failed=0 192.168.61.14 : ok=6 changed=0 unreachable=0 failed=0 localhost : ok=6 changed=0 unreachable=0 failed=0","title":"Adding Additional  Play"},{"location":"playbooks/#limiting-the-execution-to-a-particular-group","text":"Now run the following command to restrict the playbook execution to app servers ansible-playbook systems.yml --limit app This will give us the following output, plays will be executed only on app servers... PLAY [Base Configurations for ALL hosts] *************************************** TASK [setup] ******************************************************************* ok: [192.168.61.13] ok: [192.168.61.12] ......... TASK [start ntp service] ******************************************************* ok: [192.168.61.12] ok: [192.168.61.13] PLAY [App Server Configurations] *********************************************** ........ TASK [install git] ************************************************************* ok: [192.168.61.12] ok: [192.168.61.13] PLAY RECAP ********************************************************************* 192.168.61.12 : ok=9 changed=0 unreachable=0 failed=0 192.168.61.13 : ok=9 changed=0 unreachable=0 failed=0","title":"Limiting the execution to a particular group"},{"location":"playbooks/#exercises","text":"","title":"Exercises:"},{"location":"playbooks/#nano-project-create-a-playbook-with-the-following-specifications","text":"It should apply only on local host (ansible host) Should use become method Should create a user called webadmin with shell as \"/bin/sh\" Should install and start nginx service Should deploy a sample html app into the default web root directory of nginx using ansible's git module. Source repo: https://github.com/schoolofdevops/html-sample-app Deploy Path : /usr/share/nginx/html/app Once deployed, validate the site by visting http://CONTROL_HOST_IP/app","title":"Nano Project: Create a Playbook with the following specifications,"},{"location":"playbooks/#exercise-disable-facts-gathering","text":"Run ansible playbook and observe the output Add the following configuration parameter to ansible.cfg gathering = explicit Launch ansible playbook run again, observe the output and compare it with the previous run.","title":"Exercise: Disable Facts Gathering"},{"location":"preface/","text":"Preface This is an example of \"frontmatter\", which comes before the main text of the book.","title":"Preface"},{"location":"preface/#preface","text":"This is an example of \"frontmatter\", which comes before the main text of the book.","title":"Preface"},{"location":"registered_variables/","text":"(src: http://docs.ansible.com/ansible/test_strategies.html) tasks: action: uri url=http://www.example.com return_content=yes register: webpage fail: msg='service is not happy' when: \"'AWESOME' not in webpage.content\" tasks: shell: /usr/bin/some-command --parameter value register: cmd_result assert: that: - \"'not ready' not in cmd_result.stderr\" - \"'gizmo enabled' in cmd_result.stdout\" tasks: stat: path=/path/to/something register: p assert: that: - p.stat.exists and p.stat.isdir","title":"Registered Variable"},{"location":"roles/","text":"Configuring app server environment with Roles In the previous chapter, you have created and applied playbook for base systems configurations. Now is the time to start creating modular, reusable library of code for application configurations. In this chapter, we are going to write such modular code, in the form of roles and setup application server. We are going to create the roles with following specs, apache role which will Install httpd package configure httpd.conf Start httpd service Add a handler to restart service php role to install php and php-mysql restart apache when packages are installed We will also refactor systems.yml and move all the tasks to its own role i.e. systems Creating Role Scaffolding for Apache Change working directory to chap6 cd chap6 Create roles directory mkdir roles Generate role scaffolding using ansible-galaxy ansible-galaxy init --offline --init-path=roles apache Validate tree roles/ [Output] roles/ \u2514\u2500\u2500 apache \u251c\u2500\u2500 defaults \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 files \u251c\u2500\u2500 handlers \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 meta \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 README.md \u251c\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 templates \u251c\u2500\u2500 tests \u2502 \u251c\u2500\u2500 inventory \u2502 \u2514\u2500\u2500 test.yml \u2514\u2500\u2500 vars \u2514\u2500\u2500 main.yml Writing Tasks to Install and Start Apache Web Service We are going to create three different tasks files, one for each phase of application lifecycle * Install * Configure * Start Service To begin with, in this part, we will install and start apache. To install apache, Create roles/apache/tasks/install.yml --- - name: install apache web server yum: name: httpd state: installed To start the service, create roles/apache/tasks/service.yml with the following content --- - name: start apache webserver service: name: httpd state: started enabled: true To have these tasks being called, include them into main task. Edit roles/apache/tasks/main.yml --- # tasks file for apache - import_tasks: install.yml - import_tasks: service.yml Create and apply playbook to configure app servers Create a playbook for app servers app.yml with following contents --- - hosts: app become: true roles: - apache Apply app.yml with ansible-playbook ansible-playbook app.yml [Output] PLAY [Playbook to configure App Servers] ********************************************************************* TASK [setup] ******************************************************************* ok: [192.168.61.12] ok: [192.168.61.13] TASK [apache : Install Apache...] ********************************************** changed: [192.168.61.13] changed: [192.168.61.12] TASK [apache : Starting Apache...] ********************************************* changed: [192.168.61.13] changed: [192.168.61.12] PLAY RECAP ********************************************************************* 192.168.61.12 : ok=3 changed=2 unreachable=0 failed=0 192.168.61.13 : ok=3 changed=2 unreachable=0 failed=0 Managing Configurations Copy index.html and httpd.conf from chap6/helper to /roles/apache/files/ directory cd chap6 cp helper/httpd.conf roles/apache/files/ Create a task file at roles/apache/tasks/config.yml to copy the configuration file. --- - name: copy over httpd configs copy: src: httpd.conf dest: /etc/httpd.conf owner: root group: root mode: 0644 Adding Notifications and Handlers Previously we have create a task in roles/apache/tasks/config.yml to copy over httpd.conf to the app server. Update this file to send a notification to restart service on configuration update. You simply have to add the line which starts with notify --- - name: copy over httpd configs copy: src: httpd.conf dest: /etc/httpd.conf owner: root group: root mode: 0644 notify: Restart apache service Create the notification handler by updating roles/apache/handlers/main.yml --- - name: Restart apache service service: name=httpd state=restarted Update tasks/main.yml to call the newly created tasks file. --- # tasks file for apache - import_tasks: install.yml - import_tasks: service.yml - import_tasks: config.yml Apply and validate if the configuration file is being copied and service restarted. ansible-playbook app.yml Create a role to install php Generate roles scaffold ansible-galaxy init --offline --init-path=roles php roles/php/tasks/install.yml --- # install php related packages - name: install php package: name: \"{{ item }}\" state: installed with_items: - php - php-mysql notify: Restart apache service file: roles/php/tasks/main.yml --- # tasks file for php - import_tasks: install.yml Update app.yml playbook to invoke php role. file: app.yml --- - hosts: app become: true roles: - apache - php Apply the playbook ansible-playbook app.yml Systems role, dependencies and nested roles You have already written a playbook to define common systems configurations. Now, go ahead and refactor it so that instead of calling tasks from playbook itself, it goes into its own role, and then call on each server. Create a base role with ansible-galaxy utility, ansible-galaxy init --offline --init-path=roles systems Copy over the tasks from systems.yml and lets just add it to /roles/base/tasks/main.yml --- # tasks file for systems - name: remove user dojo user: > name=dojo state=absent - name: install tree utility yum: > name=tree state=present - name: install ntp yum: > name=ntp state=installed Define systems role as a dependency for apache role, Update meta data for Apache by editing roles/apache/meta/main.yml and adding the following --- dependencies: - {role: systems} Next time you run app.yml , observe if the above tasks get invoked as well. Creating a Site Wide Playbook We will create a site wide playbook, which will call all the plays required to configure the complete infrastructure. Currently we have a single playbook for App Servers. However, in future we would create many. Create site.yml in /vagrant/chap5 directory and add the following content --- # This is a sitewide playbook # filename: site.yml - import_playbook: app.yml Execute sitewide playbook as ansible-playbook site.yml [Output] PLAY [Playbook to configure App Servers] *************************************** TASK [setup] ******************************************************************* ok: [192.168.61.12] ok: [192.168.61.13] TASK [base : create admin user] ************************************************ ok: [192.168.61.12] ok: [192.168.61.13] TASK [base : remove dojo] ****************************************************** ok: [192.168.61.12] ok: [192.168.61.13] TASK [base : install tree] ***************************************************** ok: [192.168.61.13] ok: [192.168.61.12] TASK [base : install ntp] ****************************************************** ok: [192.168.61.13] ok: [192.168.61.12] TASK [base : start ntp service] ************************************************ ok: [192.168.61.13] ok: [192.168.61.12] TASK [apache : Installing Apache...] ******************************************* ok: [192.168.61.13] ok: [192.168.61.12] TASK [apache : Starting Apache...] ********************************************* ok: [192.168.61.13] ok: [192.168.61.12] TASK [apache : Copying configuration files...] ********************************* ok: [192.168.61.12] ok: [192.168.61.13] TASK [apache : Copying index.html file...] ************************************* ok: [192.168.61.12] ok: [192.168.61.13] PLAY RECAP ********************************************************************* 192.168.61.12 : ok=10 changed=0 unreachable=0 failed=0 192.168.61.13 : ok=10 changed=0 unreachable=0 failed=0 Exercises Nano Project: Deploy a PHP Application devops-demo-app is an application written in PHP. You have already setup the environment above with apache and php roles, to deploy this application. Your job is to write the ansible code to deploy this application on app servers. This code will be in the form of a role. You have been tasked to create a froentend role with the following specs, Pull release packages from the github release page as provided in the resources below. Releases are in the form of an archive. Multiple copies of releases will be maintained on the app servers for enabling rollbacks. To support this, every time to deploy a new version of the app, create a new directory for it inside the /opt/app e.g. opt | __ app \\__ release | |____ devops-demo-app-1.0 | |____ devops-demo-app-1.1 Create a symlink from the current version path to /var/www/html/app e.g. [root@app2 /]# ls -l /var/www/html/ total 8 lrwxrwxrwx 1 root root 36 Jan 16 13:28 app -> /opt/app/release/devops-demo-app-1.1 Resources : PHP App Source : https://github.com/devopsdemoapps/devops-demo-app Releases : https://github.com/devopsdemoapps/devops-demo-app/releases Once deployed, visiting for app1 or with port 82 for (app2) should show the web app deployed.","title":"Configuring app server environment with Roles"},{"location":"roles/#configuring-app-server-environment-with-roles","text":"In the previous chapter, you have created and applied playbook for base systems configurations. Now is the time to start creating modular, reusable library of code for application configurations. In this chapter, we are going to write such modular code, in the form of roles and setup application server. We are going to create the roles with following specs, apache role which will Install httpd package configure httpd.conf Start httpd service Add a handler to restart service php role to install php and php-mysql restart apache when packages are installed We will also refactor systems.yml and move all the tasks to its own role i.e. systems","title":"Configuring app server environment with Roles"},{"location":"roles/#creating-role-scaffolding-for-apache","text":"Change working directory to chap6 cd chap6 Create roles directory mkdir roles Generate role scaffolding using ansible-galaxy ansible-galaxy init --offline --init-path=roles apache Validate tree roles/ [Output] roles/ \u2514\u2500\u2500 apache \u251c\u2500\u2500 defaults \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 files \u251c\u2500\u2500 handlers \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 meta \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 README.md \u251c\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 templates \u251c\u2500\u2500 tests \u2502 \u251c\u2500\u2500 inventory \u2502 \u2514\u2500\u2500 test.yml \u2514\u2500\u2500 vars \u2514\u2500\u2500 main.yml","title":"Creating Role Scaffolding for Apache"},{"location":"roles/#writing-tasks-to-install-and-start-apache-web-service","text":"We are going to create three different tasks files, one for each phase of application lifecycle * Install * Configure * Start Service To begin with, in this part, we will install and start apache. To install apache, Create roles/apache/tasks/install.yml --- - name: install apache web server yum: name: httpd state: installed To start the service, create roles/apache/tasks/service.yml with the following content --- - name: start apache webserver service: name: httpd state: started enabled: true To have these tasks being called, include them into main task. Edit roles/apache/tasks/main.yml --- # tasks file for apache - import_tasks: install.yml - import_tasks: service.yml","title":"Writing Tasks to Install and Start  Apache Web Service"},{"location":"roles/#create-and-apply-playbook-to-configure-app-servers","text":"Create a playbook for app servers app.yml with following contents --- - hosts: app become: true roles: - apache Apply app.yml with ansible-playbook ansible-playbook app.yml [Output] PLAY [Playbook to configure App Servers] ********************************************************************* TASK [setup] ******************************************************************* ok: [192.168.61.12] ok: [192.168.61.13] TASK [apache : Install Apache...] ********************************************** changed: [192.168.61.13] changed: [192.168.61.12] TASK [apache : Starting Apache...] ********************************************* changed: [192.168.61.13] changed: [192.168.61.12] PLAY RECAP ********************************************************************* 192.168.61.12 : ok=3 changed=2 unreachable=0 failed=0 192.168.61.13 : ok=3 changed=2 unreachable=0 failed=0","title":"Create and apply playbook to configure app servers"},{"location":"roles/#managing-configurations","text":"Copy index.html and httpd.conf from chap6/helper to /roles/apache/files/ directory cd chap6 cp helper/httpd.conf roles/apache/files/ Create a task file at roles/apache/tasks/config.yml to copy the configuration file. --- - name: copy over httpd configs copy: src: httpd.conf dest: /etc/httpd.conf owner: root group: root mode: 0644","title":"Managing Configurations"},{"location":"roles/#adding-notifications-and-handlers","text":"Previously we have create a task in roles/apache/tasks/config.yml to copy over httpd.conf to the app server. Update this file to send a notification to restart service on configuration update. You simply have to add the line which starts with notify --- - name: copy over httpd configs copy: src: httpd.conf dest: /etc/httpd.conf owner: root group: root mode: 0644 notify: Restart apache service Create the notification handler by updating roles/apache/handlers/main.yml --- - name: Restart apache service service: name=httpd state=restarted Update tasks/main.yml to call the newly created tasks file. --- # tasks file for apache - import_tasks: install.yml - import_tasks: service.yml - import_tasks: config.yml Apply and validate if the configuration file is being copied and service restarted. ansible-playbook app.yml","title":"Adding Notifications and Handlers"},{"location":"roles/#create-a-role-to-install-php","text":"Generate roles scaffold ansible-galaxy init --offline --init-path=roles php roles/php/tasks/install.yml --- # install php related packages - name: install php package: name: \"{{ item }}\" state: installed with_items: - php - php-mysql notify: Restart apache service file: roles/php/tasks/main.yml --- # tasks file for php - import_tasks: install.yml Update app.yml playbook to invoke php role. file: app.yml --- - hosts: app become: true roles: - apache - php Apply the playbook ansible-playbook app.yml","title":"Create a role to install php"},{"location":"roles/#systems-role-dependencies-and-nested-roles","text":"You have already written a playbook to define common systems configurations. Now, go ahead and refactor it so that instead of calling tasks from playbook itself, it goes into its own role, and then call on each server. Create a base role with ansible-galaxy utility, ansible-galaxy init --offline --init-path=roles systems Copy over the tasks from systems.yml and lets just add it to /roles/base/tasks/main.yml --- # tasks file for systems - name: remove user dojo user: > name=dojo state=absent - name: install tree utility yum: > name=tree state=present - name: install ntp yum: > name=ntp state=installed Define systems role as a dependency for apache role, Update meta data for Apache by editing roles/apache/meta/main.yml and adding the following --- dependencies: - {role: systems} Next time you run app.yml , observe if the above tasks get invoked as well.","title":"Systems role, dependencies and nested roles"},{"location":"roles/#creating-a-site-wide-playbook","text":"We will create a site wide playbook, which will call all the plays required to configure the complete infrastructure. Currently we have a single playbook for App Servers. However, in future we would create many. Create site.yml in /vagrant/chap5 directory and add the following content --- # This is a sitewide playbook # filename: site.yml - import_playbook: app.yml Execute sitewide playbook as ansible-playbook site.yml [Output] PLAY [Playbook to configure App Servers] *************************************** TASK [setup] ******************************************************************* ok: [192.168.61.12] ok: [192.168.61.13] TASK [base : create admin user] ************************************************ ok: [192.168.61.12] ok: [192.168.61.13] TASK [base : remove dojo] ****************************************************** ok: [192.168.61.12] ok: [192.168.61.13] TASK [base : install tree] ***************************************************** ok: [192.168.61.13] ok: [192.168.61.12] TASK [base : install ntp] ****************************************************** ok: [192.168.61.13] ok: [192.168.61.12] TASK [base : start ntp service] ************************************************ ok: [192.168.61.13] ok: [192.168.61.12] TASK [apache : Installing Apache...] ******************************************* ok: [192.168.61.13] ok: [192.168.61.12] TASK [apache : Starting Apache...] ********************************************* ok: [192.168.61.13] ok: [192.168.61.12] TASK [apache : Copying configuration files...] ********************************* ok: [192.168.61.12] ok: [192.168.61.13] TASK [apache : Copying index.html file...] ************************************* ok: [192.168.61.12] ok: [192.168.61.13] PLAY RECAP ********************************************************************* 192.168.61.12 : ok=10 changed=0 unreachable=0 failed=0 192.168.61.13 : ok=10 changed=0 unreachable=0 failed=0","title":"Creating a Site Wide Playbook"},{"location":"roles/#exercises","text":"","title":"Exercises"},{"location":"roles/#nano-project-deploy-a-php-application","text":"devops-demo-app is an application written in PHP. You have already setup the environment above with apache and php roles, to deploy this application. Your job is to write the ansible code to deploy this application on app servers. This code will be in the form of a role. You have been tasked to create a froentend role with the following specs, Pull release packages from the github release page as provided in the resources below. Releases are in the form of an archive. Multiple copies of releases will be maintained on the app servers for enabling rollbacks. To support this, every time to deploy a new version of the app, create a new directory for it inside the /opt/app e.g. opt | __ app \\__ release | |____ devops-demo-app-1.0 | |____ devops-demo-app-1.1 Create a symlink from the current version path to /var/www/html/app e.g. [root@app2 /]# ls -l /var/www/html/ total 8 lrwxrwxrwx 1 root root 36 Jan 16 13:28 app -> /opt/app/release/devops-demo-app-1.1 Resources : PHP App Source : https://github.com/devopsdemoapps/devops-demo-app Releases : https://github.com/devopsdemoapps/devops-demo-app/releases Once deployed, visiting for app1 or with port 82 for (app2) should show the web app deployed.","title":"Nano Project: Deploy a PHP Application"},{"location":"setup/","text":"Settig up Learning Environment Option 1: Setting up a Vagrant based environment Install VirtualBox and Vagrant TOOL VERSION LINK VirtualBox 5.1.26 https://www.virtualbox.org/wiki/Downloads Vagrant 1.9.7 https://www.vagrantup.com/downloads.html Importing a VM Template vagrant box list vagrant box add ansible codespace-ansible-ubuntu1604-9.box vagrant box list Provisioning Vagrant Nodes Clone repo if not already git clone https://github.com/schoolofdevops/lab-setup.git Launch environments with Vagrant cd lab-setup/ansible/codespace vagrant up Login to node Terminal cd lab-setup/ansible/codespace vagrant ssh sudo su You could also visit to access the codespaces env. Option 2: Setting up a codespaces environment with Docker Clone the git repo git clone https://github.com/codespaces-io/codespaces.git Start Codespaces IDE After installing Docker-Engine and Docker-Compose, change directory into the corresponding tool you want to learn. For example, let us assume that you want to learn puppet. In that case, cd cs-ansible Then all you need to do is to run docker-compose up -d This single command will initialize your Codespaces IDE. Use Codespaces IDE To use Codespaces IDE, Open your browser. Visit your machine's IP with port 8000. (Ex. http://192.168.0.60:8080) You will be asked for your e-mail address. Enter it and you are good to go. Now you will be presented with the Codespaces IDE console.","title":"Setting up the Environment"},{"location":"setup/#settig-up-learning-environment","text":"","title":"Settig up Learning Environment"},{"location":"setup/#option-1-setting-up-a-vagrant-based-environment","text":"","title":"Option 1: Setting up a Vagrant based environment"},{"location":"setup/#install-virtualbox-and-vagrant","text":"TOOL VERSION LINK VirtualBox 5.1.26 https://www.virtualbox.org/wiki/Downloads Vagrant 1.9.7 https://www.vagrantup.com/downloads.html","title":"Install VirtualBox and Vagrant"},{"location":"setup/#importing-a-vm-template","text":"vagrant box list vagrant box add ansible codespace-ansible-ubuntu1604-9.box vagrant box list","title":"Importing a  VM Template"},{"location":"setup/#provisioning-vagrant-nodes","text":"Clone repo if not already git clone https://github.com/schoolofdevops/lab-setup.git Launch environments with Vagrant cd lab-setup/ansible/codespace vagrant up Login to node Terminal cd lab-setup/ansible/codespace vagrant ssh sudo su You could also visit to access the codespaces env.","title":"Provisioning Vagrant Nodes"},{"location":"setup/#option-2-setting-up-a-codespaces-environment-with-docker","text":"Clone the git repo git clone https://github.com/codespaces-io/codespaces.git","title":"Option 2: Setting up a codespaces environment  with Docker"},{"location":"setup/#start-codespaces-ide","text":"After installing Docker-Engine and Docker-Compose, change directory into the corresponding tool you want to learn. For example, let us assume that you want to learn puppet. In that case, cd cs-ansible Then all you need to do is to run docker-compose up -d This single command will initialize your Codespaces IDE.","title":"Start Codespaces IDE"},{"location":"setup/#use-codespaces-ide","text":"To use Codespaces IDE, Open your browser. Visit your machine's IP with port 8000. (Ex. http://192.168.0.60:8080) You will be asked for your e-mail address. Enter it and you are good to go. Now you will be presented with the Codespaces IDE console.","title":"Use Codespaces IDE"},{"location":"templates_and_variables/","text":"Templates and Variables In this tutorial, we are going to make the roles that we created earlier dynamically by adding templates and defining variables. Variables Variables are of two types Automatic Variables/ Facts User Defined Variables Lets try to discover information about our systems by using facts. Finding Facts About Systems Run the following command to see to facts of db servers cd chap7 ansible db -m setup [Output] 192.168.61.11 | SUCCESS => { \"ansible_facts\": { \"ansible_all_ipv4_addresses\": [ \"10.0.2.15\", \"192.168.61.11\" ], \"ansible_all_ipv6_addresses\": [ \"fe80::a00:27ff:fe30:3251\", \"fe80::a00:27ff:fe8e:83e0\" ..... \"tz_offset\": \"+0100\", \"weekday\": \"Monday\", \"weekday_number\": \"1\", \"weeknumber\": \"36\", \"year\": \"2016\" } Filtering facts Use filter attribute to extract specific data ansible db -m setup -a \"filter=ansible_distribution\" [Output] 192.168.61.11 | SUCCESS => { \"ansible_facts\": { \"ansible_distribution\": \"CentOS\" }, \"changed\": false } Defining release versions with vars Currently, while deploying the application, the versions of the artifacts as well as release directories are defined statically. This should change to vars so that the version can be defined from one place, and dynamically so. Define the default vars file: roles/frontend/defaults/main.yml --- # defaults file for frontend app: version: 1.5 Update tasks to use the var defined above, wherever you see version number e.g. 1.1, replace that with {{ app.version }} var. file: roles/frontend/tasks/main.yml - name: Download and extract the release unarchive: src: https://github.com/devopsdemoapps/devops-demo-app/archive/{{ app.version }}.tar.gz dest: /opt/app/release owner: apache group: apache creates: /opt/app/release/devops-demo-app-{{ app.version }} remote_src: yes - name: create a symlink file: src: /opt/app/release/devops-demo-app-{{ app.version }} dest: /var/www/html/app owner: apache group: apache state: link Try This : * Run playbook and check whether the above code works * Change the version e.g. 1.4 and check if it has any effect Creating application configurations dynamically Application configs are defined with config.ini file. The version of config.ini as shipped with the application is as follows, [database] hostname = DBHOST username = SQLUSER password = SQLPASSWORD dbname = SQLDBNAME [environment] environment = ENVNAME [prefs] color = white fruit = apple car = fiat laptop = dell You should be able to customize these configs. In order to do that, you need to do split this into 2 things as follows, vars which define the actual properties and allow you to change it from different places a jinja2 template which will collect and process the vars on the fly and create the resulting configs dynamically Defining the vars for app config file: roles/frontend/defaults/main.yml --- # defaults file for frontend app: version: 1.5 env: LOCALDEV fav: color: white fruit: orange car: chevy laptop: toshiba dbconn: host: localhost user: root pass: changeme db: devopsdemo Create directory and template file. You could either use the commands below or directly create it from the graphical editor. cd roles/frontend mkdir templates touch templates/config.ini.j2 file: roles/frontend/templates/config.ini.j2 [database] hostname = {{ dbconn['host'] }} username = {{ dbconn['user'] }} password = {{ dbconn['pass'] }} dbname = {{ dbconn['db'] }} [environment] environment = {{ app['env'] }} [prefs] color = {{ fav['color'] }} fruit = {{ fav['fruit'] }} car = {{ fav['car'] }} laptop = {{ fav['laptop'] }} Adding task to generate the config from jinja2 template file: roles/frontend/tasks/main.yml ( append the following code to the file) - name: add application configs template: src: config.ini.j2 dest: /var/www/html/app/config.ini owner: apache group: apache mode: 0644 Now, run the playbook, reload the application page and validate. You should also browse to http://IPADDRESS:81/app/prefs.php to view if it prints the preferences you defined in the default vars. cd chap7 ansible-playbook app.yml Beyond defaults - Playing with vars precedence Lets define the variables from couple of other places, to learn about the Precedence rules. We will create, group_vars playbook vars Since we are going to define the variables using multi level hashes, define the way hashes behave when defined from multiple places. Update chap7/ansible.cfg and add the following, hash_behaviour=merge Lets create group_vars and create a group prod to define vars common to all prod hosts. cd chap7 mkdir group_vars cd group_vars touch prod.yml Edit group_vars/prod.yml file and add the following contents, --- fav: color: yellow fruit: guava Lets also add vars to playbook. Edit app.yml and add vars as below, --- - hosts: app become: true vars: fav: fruit: mango roles: - apache - php - frontend Execute the playbook and check the output ansible-playbook app.yml If you view the content of the html file generated, you would notice the following, <h3> color : yellow </h3> <h3> fruit : mango </h3> <h3> car : chevy </h3> <h3> laptop : toshiba </h3> fav item role defaults group_vars playbook_vars color white yellow fruit orange guava mango car chevy laptop toshiba value of color comes from group_vars/all.yml value of fruit comes from playbook vars value of car and laptop comes from role defaults Registered Variables Lets create a playbook to run a shell command, register the result and display the value of registered variable. Create register.yml in chap7 directory --- - name: register variable example hosts: local tasks: - name: install net tools to make ifconfig command available package: name: net-tools state: installed - name: run a shell command and register result shell: \"/sbin/ifconfig eth0\" register: result - name: print registered variable debug: var=result Execute the playbook to display information about the registered variable. ansible-playbook register.yml Adding support for Ubuntu Apache role that we have developed supports only RedHat based systems at the moment. To add support for ubuntu (app2), we must handle platform specific differences. e.g. RedHat Debian Package Name httpd apache2 Service Name httpd apache2 OS specific configurations can be defined by creating role vars and by including those in tasks. file: roles/apache/vars/RedHat.yml --- apache: package: name: httpd service: name: httpd status: started file: roles/apache/vars/Debian.yml --- apache: package: name: apache2 service: name: apache2 status: started Lets now selectively include those var files from tasks/main.yml . Also selectively call configurations. file: role/apache/tasks/main.yml --- # tasks file for apache - include_vars: \"{{ ansible_os_family }}.yml\" - include: install.yml - include: service.yml - include: config_{{ ansible_os_family }}.yml We are now going to create two different config tasks. Since the current config is applicable to RedHat, lets rename it to config_RedHat.yml mv roles/apache/tasks/config.yml roles/apache/tasks/config_RedHat.yml We will now create a new config for Debian file: roles/apache/tasks/config_Debian.yml - name: Copying index.html file... template: > src=index.html.j2 dest=/var/www/html/index.html mode=0777 Update tasks and handlers to install and start the correct service tasks/install.yml --- - name: install httpd on centos package: > name={{ apache['package']['name']}} state=installed tasks/service.yml --- - name: start httpd service service: > name={{ apache['service']['name']}} state={{ apache['service']['status']}} handlers/main.yml --- # handlers file for apache - name: restart apache service service: > name={{ apache['service']['name']}} state=restarted Now add host app3 to the inventory file: environments/prod [app] app1 app2 app3 ansible_password=codespaces and apply playbook ansible-playbook app.yml Exercises Create host specific variables in host_vars/HOSTNAME for one of the app servers, and define some variables values specific to the host. See the output after applying playbook on this node. Generate MySQL Configurations dynamically using templates and modules. Create a template for my.cnf. Name it as roles/mysql/templates/my.cnf.j2 Replace parameter values with templates variables Define variables in role defaults.","title":"Making roles reusable with vars and templates"},{"location":"templates_and_variables/#templates-and-variables","text":"In this tutorial, we are going to make the roles that we created earlier dynamically by adding templates and defining variables.","title":"Templates and Variables"},{"location":"templates_and_variables/#variables","text":"Variables are of two types Automatic Variables/ Facts User Defined Variables Lets try to discover information about our systems by using facts.","title":"Variables"},{"location":"templates_and_variables/#finding-facts-about-systems","text":"Run the following command to see to facts of db servers cd chap7 ansible db -m setup [Output] 192.168.61.11 | SUCCESS => { \"ansible_facts\": { \"ansible_all_ipv4_addresses\": [ \"10.0.2.15\", \"192.168.61.11\" ], \"ansible_all_ipv6_addresses\": [ \"fe80::a00:27ff:fe30:3251\", \"fe80::a00:27ff:fe8e:83e0\" ..... \"tz_offset\": \"+0100\", \"weekday\": \"Monday\", \"weekday_number\": \"1\", \"weeknumber\": \"36\", \"year\": \"2016\" }","title":"Finding Facts About Systems"},{"location":"templates_and_variables/#filtering-facts","text":"Use filter attribute to extract specific data ansible db -m setup -a \"filter=ansible_distribution\" [Output] 192.168.61.11 | SUCCESS => { \"ansible_facts\": { \"ansible_distribution\": \"CentOS\" }, \"changed\": false }","title":"Filtering facts"},{"location":"templates_and_variables/#defining-release-versions-with-vars","text":"Currently, while deploying the application, the versions of the artifacts as well as release directories are defined statically. This should change to vars so that the version can be defined from one place, and dynamically so. Define the default vars file: roles/frontend/defaults/main.yml --- # defaults file for frontend app: version: 1.5 Update tasks to use the var defined above, wherever you see version number e.g. 1.1, replace that with {{ app.version }} var. file: roles/frontend/tasks/main.yml - name: Download and extract the release unarchive: src: https://github.com/devopsdemoapps/devops-demo-app/archive/{{ app.version }}.tar.gz dest: /opt/app/release owner: apache group: apache creates: /opt/app/release/devops-demo-app-{{ app.version }} remote_src: yes - name: create a symlink file: src: /opt/app/release/devops-demo-app-{{ app.version }} dest: /var/www/html/app owner: apache group: apache state: link Try This : * Run playbook and check whether the above code works * Change the version e.g. 1.4 and check if it has any effect","title":"Defining release versions with vars"},{"location":"templates_and_variables/#creating-application-configurations-dynamically","text":"Application configs are defined with config.ini file. The version of config.ini as shipped with the application is as follows, [database] hostname = DBHOST username = SQLUSER password = SQLPASSWORD dbname = SQLDBNAME [environment] environment = ENVNAME [prefs] color = white fruit = apple car = fiat laptop = dell You should be able to customize these configs. In order to do that, you need to do split this into 2 things as follows, vars which define the actual properties and allow you to change it from different places a jinja2 template which will collect and process the vars on the fly and create the resulting configs dynamically","title":"Creating  application configurations dynamically"},{"location":"templates_and_variables/#defining-the-vars-for-app-config","text":"file: roles/frontend/defaults/main.yml --- # defaults file for frontend app: version: 1.5 env: LOCALDEV fav: color: white fruit: orange car: chevy laptop: toshiba dbconn: host: localhost user: root pass: changeme db: devopsdemo Create directory and template file. You could either use the commands below or directly create it from the graphical editor. cd roles/frontend mkdir templates touch templates/config.ini.j2 file: roles/frontend/templates/config.ini.j2 [database] hostname = {{ dbconn['host'] }} username = {{ dbconn['user'] }} password = {{ dbconn['pass'] }} dbname = {{ dbconn['db'] }} [environment] environment = {{ app['env'] }} [prefs] color = {{ fav['color'] }} fruit = {{ fav['fruit'] }} car = {{ fav['car'] }} laptop = {{ fav['laptop'] }}","title":"Defining the vars for app config"},{"location":"templates_and_variables/#adding-task-to-generate-the-config-from-jinja2-template","text":"file: roles/frontend/tasks/main.yml ( append the following code to the file) - name: add application configs template: src: config.ini.j2 dest: /var/www/html/app/config.ini owner: apache group: apache mode: 0644 Now, run the playbook, reload the application page and validate. You should also browse to http://IPADDRESS:81/app/prefs.php to view if it prints the preferences you defined in the default vars. cd chap7 ansible-playbook app.yml","title":"Adding task to generate  the  config from jinja2 template"},{"location":"templates_and_variables/#beyond-defaults-playing-with-vars-precedence","text":"Lets define the variables from couple of other places, to learn about the Precedence rules. We will create, group_vars playbook vars Since we are going to define the variables using multi level hashes, define the way hashes behave when defined from multiple places. Update chap7/ansible.cfg and add the following, hash_behaviour=merge Lets create group_vars and create a group prod to define vars common to all prod hosts. cd chap7 mkdir group_vars cd group_vars touch prod.yml Edit group_vars/prod.yml file and add the following contents, --- fav: color: yellow fruit: guava Lets also add vars to playbook. Edit app.yml and add vars as below, --- - hosts: app become: true vars: fav: fruit: mango roles: - apache - php - frontend Execute the playbook and check the output ansible-playbook app.yml If you view the content of the html file generated, you would notice the following, <h3> color : yellow </h3> <h3> fruit : mango </h3> <h3> car : chevy </h3> <h3> laptop : toshiba </h3> fav item role defaults group_vars playbook_vars color white yellow fruit orange guava mango car chevy laptop toshiba value of color comes from group_vars/all.yml value of fruit comes from playbook vars value of car and laptop comes from role defaults","title":"Beyond defaults - Playing with vars precedence"},{"location":"templates_and_variables/#registered-variables","text":"Lets create a playbook to run a shell command, register the result and display the value of registered variable. Create register.yml in chap7 directory --- - name: register variable example hosts: local tasks: - name: install net tools to make ifconfig command available package: name: net-tools state: installed - name: run a shell command and register result shell: \"/sbin/ifconfig eth0\" register: result - name: print registered variable debug: var=result Execute the playbook to display information about the registered variable. ansible-playbook register.yml","title":"Registered  Variables"},{"location":"templates_and_variables/#adding-support-for-ubuntu","text":"Apache role that we have developed supports only RedHat based systems at the moment. To add support for ubuntu (app2), we must handle platform specific differences. e.g. RedHat Debian Package Name httpd apache2 Service Name httpd apache2 OS specific configurations can be defined by creating role vars and by including those in tasks. file: roles/apache/vars/RedHat.yml --- apache: package: name: httpd service: name: httpd status: started file: roles/apache/vars/Debian.yml --- apache: package: name: apache2 service: name: apache2 status: started Lets now selectively include those var files from tasks/main.yml . Also selectively call configurations. file: role/apache/tasks/main.yml --- # tasks file for apache - include_vars: \"{{ ansible_os_family }}.yml\" - include: install.yml - include: service.yml - include: config_{{ ansible_os_family }}.yml We are now going to create two different config tasks. Since the current config is applicable to RedHat, lets rename it to config_RedHat.yml mv roles/apache/tasks/config.yml roles/apache/tasks/config_RedHat.yml We will now create a new config for Debian file: roles/apache/tasks/config_Debian.yml - name: Copying index.html file... template: > src=index.html.j2 dest=/var/www/html/index.html mode=0777 Update tasks and handlers to install and start the correct service tasks/install.yml --- - name: install httpd on centos package: > name={{ apache['package']['name']}} state=installed tasks/service.yml --- - name: start httpd service service: > name={{ apache['service']['name']}} state={{ apache['service']['status']}} handlers/main.yml --- # handlers file for apache - name: restart apache service service: > name={{ apache['service']['name']}} state=restarted Now add host app3 to the inventory file: environments/prod [app] app1 app2 app3 ansible_password=codespaces and apply playbook ansible-playbook app.yml","title":"Adding support for Ubuntu"},{"location":"templates_and_variables/#exercises","text":"Create host specific variables in host_vars/HOSTNAME for one of the app servers, and define some variables values specific to the host. See the output after applying playbook on this node. Generate MySQL Configurations dynamically using templates and modules. Create a template for my.cnf. Name it as roles/mysql/templates/my.cnf.j2 Replace parameter values with templates variables Define variables in role defaults.","title":"Exercises"},{"location":"todo/","text":"Additional chapters * Ansible Vault * Tags etc. * Managing Multiple Environments * Dynamic inventory * Ansible Tower * Ansible with Rundeck * Ansible with Docker * Ansible and windows * Running Ansible Programatically (https://github.com/jtyr/ansible-run_playbook) * Windows Integration : k d * Ansible Pull: k Stuff - dry run creating passwords : mkpasswd --method=sha-512 - assert: { that: \"ansible_os_family != 'RedHat'\" } - jinja2 filters - expect - Registered variable examples: k d Chap3: * add group of groups for inventory [blr:children] * windows inventory example * add host patterns, and filters * more examples on modules * ansible-doc -l to list modules available chap4: * Error handling in playbooks chap5: * Add a exercise to download/install a role from galaxy and apply Playbook * disable fact finding to improve performance ( gathering = implicit ) When to disable facts caching ? Additional Topics Chap 5 deprecated * Pre Task to be run before creating MySQL Role From Ansible Control node run the following command to enable repositories. This is needed in order to install some of the db packages. ansible db -s -a \"cp -r /etc/yum.repos.d/repo.bkp/* /etc/yum.repos.d/\" Notes: for notifications its good to use config and service","title":"Todo"},{"location":"todo/#notes","text":"for notifications its good to use config and service","title":"Notes:"},{"location":"troubleshooting/","text":"Troubleshooting Techniques * Using verbose mode * Using --start-at-task * Using --step * Using debugger Verbose Mode -vvvv Debugger http://docs.ansible.com/ansible/playbooks_debugger.html Defining Failure failed_when: \"'FAILED' in command_result.stderr\" http://docs.ansible.com/ansible/playbooks_error_handling.html start-at-task ansible-playbook playbook.yml --start-at-task=\"install packages\" Step Playbooks can also be executed interactively with --step: ansible-playbook playbook.yml --step This will cause ansible to stop on each t http://docs.ansible.com/ansible/playbooks_startnstep.html","title":"Troubleshooting Techniques"},{"location":"update/","text":"Updating Application Writing database schema update playbook The following url has the links to the database dumps Database SQL Dumps Lets write tasks to update schema for database file: db.yml --- - name: playbook to configure db servers hosts: db become: yes roles: - { role: geerlingguy.mysql } tasks: - name: download database schema get_url: url: https://raw.githubusercontent.com/devopsdemoapps/devops-demo-app/master/data/devops-demo-1.0.sql dest: /tmp/devops-demo-1.0.sql mode: 0444 tags: schema - name: Schema Migrate mysql_db: name: \"{{ dbconn.db }}\" login_host: \"127.0.0.1\" login_password: \"{{ mysql_root_password }}\" login_user: \"root\" state: import target: /tmp/devops-demo-1.0.sql tags: schema where, * we have added task to download the schema file from a remote uri * load the schema using import state Its important to use 1.0 as the schema version first time you run as it needs the initial tables. Run it for the first time, ansible-playbook db.yml --vault-id prod@~/.vault_prod --tags=schema Once the initial schema apply is done, update the tasks to use app.version for schema update as well --- - name: playbook to configure db servers hosts: db become: yes roles: - { role: geerlingguy.mysql } tasks: - name: download database schema get_url: url: https://raw.githubusercontent.com/devopsdemoapps/devops-demo-app/master/data/devops-demo-{{ app.version }}.sql dest: /tmp/devops-demo-{{ app.version }}.sql mode: 0444 tags: schema - name: Schema Migrate mysql_db: name: \"{{ dbconn.db }}\" login_host: \"127.0.0.1\" login_password: \"{{ mysql_root_password }}\" login_user: \"root\" state: import target: /tmp/devops-demo-{{ app.version }}.sql tags: schema Deployment Playbook Strategy: * Rolling updates/zero downtime * Batch size = 1 Deployment strategy and sequence, * Update database schema * For each web server update * Disable load balancer traffic * Deploy new version of the application * Wait for the app to be available * Enable traffic from load balancer Pre tasks file: deployment.yml - hosts: app become: yes vars: app: version: 1.6 serial: 1 pre_tasks: - name: take the app server out haproxy: host: '{{ inventory_hostname }}' state: disabled delegate_to: lb roles: - frontend post_tasks: - name: Wait 300 seconds for port 80 to be available wait_for: port: 80 host: '{{ inventory_hostname }}' delay: 5 timeout: 300 connection: local - name: add server to loadbalancer haproxy: host: '{{ inventory_hostname }}' state: enabled delegate_to: lb Deploy a new version with ansible-playbook deployment.yml","title":"Setting up Zero Downtime Deployment"},{"location":"update/#updating-application","text":"","title":"Updating Application"},{"location":"update/#writing-database-schema-update-playbook","text":"The following url has the links to the database dumps Database SQL Dumps Lets write tasks to update schema for database file: db.yml --- - name: playbook to configure db servers hosts: db become: yes roles: - { role: geerlingguy.mysql } tasks: - name: download database schema get_url: url: https://raw.githubusercontent.com/devopsdemoapps/devops-demo-app/master/data/devops-demo-1.0.sql dest: /tmp/devops-demo-1.0.sql mode: 0444 tags: schema - name: Schema Migrate mysql_db: name: \"{{ dbconn.db }}\" login_host: \"127.0.0.1\" login_password: \"{{ mysql_root_password }}\" login_user: \"root\" state: import target: /tmp/devops-demo-1.0.sql tags: schema where, * we have added task to download the schema file from a remote uri * load the schema using import state Its important to use 1.0 as the schema version first time you run as it needs the initial tables. Run it for the first time, ansible-playbook db.yml --vault-id prod@~/.vault_prod --tags=schema Once the initial schema apply is done, update the tasks to use app.version for schema update as well --- - name: playbook to configure db servers hosts: db become: yes roles: - { role: geerlingguy.mysql } tasks: - name: download database schema get_url: url: https://raw.githubusercontent.com/devopsdemoapps/devops-demo-app/master/data/devops-demo-{{ app.version }}.sql dest: /tmp/devops-demo-{{ app.version }}.sql mode: 0444 tags: schema - name: Schema Migrate mysql_db: name: \"{{ dbconn.db }}\" login_host: \"127.0.0.1\" login_password: \"{{ mysql_root_password }}\" login_user: \"root\" state: import target: /tmp/devops-demo-{{ app.version }}.sql tags: schema","title":"Writing database schema update playbook"},{"location":"update/#deployment-playbook","text":"Strategy: * Rolling updates/zero downtime * Batch size = 1 Deployment strategy and sequence, * Update database schema * For each web server update * Disable load balancer traffic * Deploy new version of the application * Wait for the app to be available * Enable traffic from load balancer","title":"Deployment Playbook"},{"location":"update/#pre-tasks","text":"file: deployment.yml - hosts: app become: yes vars: app: version: 1.6 serial: 1 pre_tasks: - name: take the app server out haproxy: host: '{{ inventory_hostname }}' state: disabled delegate_to: lb roles: - frontend post_tasks: - name: Wait 300 seconds for port 80 to be available wait_for: port: 80 host: '{{ inventory_hostname }}' delay: 5 timeout: 300 connection: local - name: add server to loadbalancer haproxy: host: '{{ inventory_hostname }}' state: enabled delegate_to: lb Deploy a new version with ansible-playbook deployment.yml","title":"Pre tasks"},{"location":"vault/","text":"placeholder","title":"placeholder"},{"location":"vault/#placeholder","text":"","title":"placeholder"}]}